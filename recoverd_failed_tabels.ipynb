{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcEQjRJJgfcsK2oLQR8tPh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedbahaaeldien92-max/Elezaby-project/blob/main/recoverd_failed_tabels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3voPJOqgnNM9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0efdfc77"
      },
      "source": [
        "# Task\n",
        "Analyze and clean product IDs in \"products_dimension.csv\" by matching them against \"order_products_fact.csv\", recovering 'product_id' values based on exact or prefix-with-price-tolerance matches, and then categorize and summarize the recovery process. Save the recovered products to \"products_dimension_recovered.csv\" and failed recoveries to \"products_dimension_failed.csv\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c73c5761"
      },
      "source": [
        "## Load and Prepare DataFrames\n",
        "\n",
        "### Subtask:\n",
        "Load 'order_products_fact.csv' and 'products_dimension.csv' into pandas DataFrames, ensuring correct data types for 'product_id' and 'unit_price'. Initialize a 'recovered_product_id' column and a recovery status flag in the 'products_dimension' DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b15eda5"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll import the pandas library to enable data manipulation. Then, I'll load both CSV files into pandas DataFrames, `fact_df` and `products_df`, specifying the correct data types for 'product_id' and 'unit_price' as requested. After loading, I'll initialize the 'recovered_product_id' and 'is_recovered' columns in the `products_df`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ca1106c",
        "outputId": "7b1734a3-0a15-43a4-87e4-238e8289b323"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load 'order_products_fact.csv' into fact_df\n",
        "fact_df = pd.read_csv(\n",
        "    '/content/order_products_fact.csv',\n",
        "    dtype={'product_id': str, 'unit_price': float}\n",
        ")\n",
        "\n",
        "# Load 'products_dimension.csv' into products_df\n",
        "products_df = pd.read_csv(\n",
        "    '/content/products_dimension.csv',\n",
        "    dtype={'product_id': str, 'unit_price': float}\n",
        ")\n",
        "\n",
        "# Create 'recovered_product_id' column in products_df\n",
        "products_df['recovered_product_id'] = products_df['product_id']\n",
        "\n",
        "# Create 'is_recovered' boolean column in products_df and initialize to False\n",
        "products_df['is_recovered'] = False\n",
        "\n",
        "print(\"DataFrames 'fact_df' and 'products_df' loaded and prepared.\")\n",
        "print(\"fact_df head:\")\n",
        "print(fact_df.head())\n",
        "print(\"\\nproducts_df head:\")\n",
        "print(products_df.head())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrames 'fact_df' and 'products_df' loaded and prepared.\n",
            "fact_df head:\n",
            "   order_id     product_id  quantity  unit_price   sales\n",
            "0  O1000000  6251001217308         1       85.79   85.79\n",
            "1  O1000000        3500958         4       24.94   99.76\n",
            "2  O1000000        6000400         2       12.55   25.10\n",
            "3  O1000000         121018         2       77.30  154.60\n",
            "4  O1000000        2705575         1       58.66   58.66\n",
            "\n",
            "products_df head:\n",
            "    product_id                              product_name         Brand  \\\n",
            "0  5.28102E+12          BEESLINE ELDER ROSE DEO R.ON 50M  BEESLINE DEO   \n",
            "1  5.28102E+12  BEESLINE GREEN FORST WHIT.R.ON DEOD.50M#  BEESLINE DEO   \n",
            "2  5.28102E+12    BEESLINE PACIFIC ISLANDS DEO R.ON 50M#  BEESLINE DEO   \n",
            "3  5.28102E+12         BEESLINE COOL BREEZE DEO R.ON 50M  BEESLINE DEO   \n",
            "4  5.28102E+12        BEESLINE HR DELAYING DEO R.ON 50M#  BEESLINE DEO   \n",
            "\n",
            "              Division         Category      Subcategory         Segment  \\\n",
            "0  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "1  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "2  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "3  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "4  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "\n",
            "   unit_price recovered_product_id  is_recovered  \n",
            "0       40.58          5.28102E+12         False  \n",
            "1       95.32          5.28102E+12         False  \n",
            "2       74.54          5.28102E+12         False  \n",
            "3       61.87          5.28102E+12         False  \n",
            "4       19.82          5.28102E+12         False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2be4b893"
      },
      "source": [
        "## Clean Product IDs in Products Dimension\n",
        "\n",
        "### Subtask:\n",
        "Clean the 'product_id' column in the `products_df` DataFrame by removing trailing '.0', converting scientific notation to standard numeric strings, and removing all non-numeric characters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e1d21f8"
      },
      "source": [
        "**Reasoning**:\n",
        "The current subtask requires cleaning the 'product_id' column in the `products_df` DataFrame. This involves defining a function to handle scientific notation, remove trailing '.0', and remove non-numeric characters, then applying it to the column. I will also display the head of the DataFrame and its dtypes to verify the cleaning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18b7be67",
        "outputId": "ae840e8f-99cf-4af6-9810-083050ed063a"
      },
      "source": [
        "import re\n",
        "\n",
        "def clean_product_id(product_id_str):\n",
        "    # Explicitly convert to string\n",
        "    product_id_str = str(product_id_str)\n",
        "\n",
        "    # Handle scientific notation: Convert to float, then to int, then to string\n",
        "    try:\n",
        "        # Check if it looks like scientific notation, but avoid converting\n",
        "        # legitimate string IDs that contain 'e' or 'E' but are not scientific numbers\n",
        "        if re.match(r'^-?\\d+(\\.\\d+)?[eE][+-]?\\d+$', product_id_str):\n",
        "            product_id_str = str(int(float(product_id_str)))\n",
        "    except ValueError:\n",
        "        pass # If it's not a valid scientific notation number, keep as is for now\n",
        "\n",
        "    # Remove trailing '.0'\n",
        "    if product_id_str.endswith('.0'):\n",
        "        product_id_str = product_id_str[:-2]\n",
        "\n",
        "    # Remove all non-digit characters\n",
        "    product_id_str = re.sub(r'\\D', '', product_id_str)\n",
        "\n",
        "    return product_id_str\n",
        "\n",
        "# Apply the cleaning function to the 'product_id' column\n",
        "products_df['product_id'] = products_df['product_id'].apply(clean_product_id)\n",
        "\n",
        "print(\"product_id column in products_df has been cleaned.\")\n",
        "print(\"\\nproducts_df head after cleaning:\")\n",
        "print(products_df.head())\n",
        "\n",
        "print(\"\\nData types of products_df after cleaning:\")\n",
        "print(products_df.dtypes)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "product_id column in products_df has been cleaned.\n",
            "\n",
            "products_df head after cleaning:\n",
            "      product_id                              product_name         Brand  \\\n",
            "0  5281020000000          BEESLINE ELDER ROSE DEO R.ON 50M  BEESLINE DEO   \n",
            "1  5281020000000  BEESLINE GREEN FORST WHIT.R.ON DEOD.50M#  BEESLINE DEO   \n",
            "2  5281020000000    BEESLINE PACIFIC ISLANDS DEO R.ON 50M#  BEESLINE DEO   \n",
            "3  5281020000000         BEESLINE COOL BREEZE DEO R.ON 50M  BEESLINE DEO   \n",
            "4  5281020000000        BEESLINE HR DELAYING DEO R.ON 50M#  BEESLINE DEO   \n",
            "\n",
            "              Division         Category      Subcategory         Segment  \\\n",
            "0  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "1  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "2  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "3  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "4  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "\n",
            "   unit_price recovered_product_id  is_recovered  \n",
            "0       40.58          5.28102E+12         False  \n",
            "1       95.32          5.28102E+12         False  \n",
            "2       74.54          5.28102E+12         False  \n",
            "3       61.87          5.28102E+12         False  \n",
            "4       19.82          5.28102E+12         False  \n",
            "\n",
            "Data types of products_df after cleaning:\n",
            "product_id               object\n",
            "product_name             object\n",
            "Brand                    object\n",
            "Division                 object\n",
            "Category                 object\n",
            "Subcategory              object\n",
            "Segment                  object\n",
            "unit_price              float64\n",
            "recovered_product_id     object\n",
            "is_recovered               bool\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13217325"
      },
      "source": [
        "## Create Canonical Reference from Fact Table\n",
        "\n",
        "### Subtask:\n",
        "From 'order_products_fact', create a reference DataFrame containing unique combinations of 'product_id' and 'unit_price'. This will be used as the authoritative source for lookup and validation. Also, identify potential initial 'damaged' product_ids in products_dimension for summary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95b69909"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll create the `canonical_products_df` from `fact_df` by selecting the 'product_id' and 'unit_price' columns and dropping duplicates. Then, I'll apply the previously defined `clean_product_id` function to its 'product_id' column. Finally, I will identify and count 'damaged' product IDs by comparing the original and cleaned 'product_id' values in `products_df`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13e5638c",
        "outputId": "4e4c76bf-e843-4611-858f-c3e438c89ede"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create canonical_products_df from fact_df\n",
        "canonical_products_df = fact_df[['product_id', 'unit_price']].drop_duplicates().copy()\n",
        "\n",
        "# Apply the cleaning function to the 'product_id' column of canonical_products_df\n",
        "canonical_products_df['product_id'] = canonical_products_df['product_id'].apply(clean_product_id)\n",
        "\n",
        "# Identify 'damaged' product_ids in products_df based on the initial cleaning step\n",
        "# We compare the 'recovered_product_id' (original value) with the 'product_id' (cleaned value)\n",
        "initial_damaged_product_ids = products_df[products_df['recovered_product_id'] != products_df['product_id']].shape[0]\n",
        "\n",
        "print(\"Canonical Products DataFrame created and cleaned.\")\n",
        "print(\"canonical_products_df head:\")\n",
        "print(canonical_products_df.head())\n",
        "\n",
        "print(f\"\\nNumber of initial 'damaged' product_ids in products_df: {initial_damaged_product_ids}\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Canonical Products DataFrame created and cleaned.\n",
            "canonical_products_df head:\n",
            "      product_id  unit_price\n",
            "0  6251001217308       85.79\n",
            "1        3500958       24.94\n",
            "2        6000400       12.55\n",
            "3         121018       77.30\n",
            "4        2705575       58.66\n",
            "\n",
            "Number of initial 'damaged' product_ids in products_df: 26084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62253125"
      },
      "source": [
        "## Attempt Exact Match Recovery\n",
        "\n",
        "### Subtask:\n",
        "Iterate through 'products_dimension'. For each row, attempt to find an exact match for its *cleaned* 'product_id' and 'unit_price' in the canonical reference created from 'order_products_fact'. If an exact match is found, update 'recovered_product_id' and mark the row as successfully recovered.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69e11894"
      },
      "source": [
        "**Reasoning**:\n",
        "I will perform an inner merge between `products_df` and `canonical_products_df` on cleaned 'product_id' and 'unit_price' to find exact matches. Then, I'll update the `is_recovered` and `recovered_product_id` columns in `products_df` for the matched rows and print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56cf7455",
        "outputId": "6524a9e1-e515-4b60-cd98-9dc2bbca263a"
      },
      "source": [
        "print(f\"Initial number of unrecovered products: {products_df[~products_df['is_recovered']].shape[0]}\")\n",
        "\n",
        "# Create a temporary DataFrame of exact matches\n",
        "merged_exact_matches = pd.merge(\n",
        "    products_df[~products_df['is_recovered']], # Only consider unrecovered products for matching\n",
        "    canonical_products_df,\n",
        "    on=['product_id', 'unit_price'],\n",
        "    how='inner'\n",
        ")\n",
        "\n",
        "# Get the indices of the products_df rows that were successfully matched\n",
        "exact_match_indices = merged_exact_matches.index\n",
        "\n",
        "# Update 'is_recovered' for these rows in products_df\n",
        "products_df.loc[exact_match_indices, 'is_recovered'] = True\n",
        "\n",
        "# Update 'recovered_product_id' for these rows in products_df\n",
        "# The product_id from products_df is already cleaned and is the one that matched\n",
        "products_df.loc[exact_match_indices, 'recovered_product_id'] = products_df.loc[exact_match_indices, 'product_id']\n",
        "\n",
        "num_exact_matches = len(exact_match_indices)\n",
        "print(f\"Number of products recovered by exact match: {num_exact_matches}\")\n",
        "print(f\"Total recovered products after exact match: {products_df['is_recovered'].sum()}\")\n",
        "print(\"\\nproducts_df head after exact match recovery:\")\n",
        "print(products_df.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of unrecovered products: 62700\n",
            "Number of products recovered by exact match: 36618\n",
            "Total recovered products after exact match: 36618\n",
            "\n",
            "products_df head after exact match recovery:\n",
            "      product_id                              product_name         Brand  \\\n",
            "0  5281020000000          BEESLINE ELDER ROSE DEO R.ON 50M  BEESLINE DEO   \n",
            "1  5281020000000  BEESLINE GREEN FORST WHIT.R.ON DEOD.50M#  BEESLINE DEO   \n",
            "2  5281020000000    BEESLINE PACIFIC ISLANDS DEO R.ON 50M#  BEESLINE DEO   \n",
            "3  5281020000000         BEESLINE COOL BREEZE DEO R.ON 50M  BEESLINE DEO   \n",
            "4  5281020000000        BEESLINE HR DELAYING DEO R.ON 50M#  BEESLINE DEO   \n",
            "\n",
            "              Division         Category      Subcategory         Segment  \\\n",
            "0  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "1  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "2  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "3  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "4  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "\n",
            "   unit_price recovered_product_id  is_recovered  \n",
            "0       40.58        5281020000000          True  \n",
            "1       95.32        5281020000000          True  \n",
            "2       74.54        5281020000000          True  \n",
            "3       61.87        5281020000000          True  \n",
            "4       19.82        5281020000000          True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4824211"
      },
      "source": [
        "## Attempt Prefix Match with Price Tolerance Recovery\n",
        "\n",
        "### Subtask:\n",
        "For rows in 'products_dimension' that were not successfully recovered by exact match: Extract the first 6 digits (prefix) from their *cleaned* 'product_id'. Search the canonical reference for product_ids that share this prefix AND have a 'unit_price' within a \\u00b10.01 tolerance of the 'unit_price' in the current 'products_dimension' row. If exactly one such match is found, update 'recovered_product_id' and mark the row as recovered. If zero or more than one match, mark the row as unrecoverable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c70dd9fc"
      },
      "source": [
        "**Reasoning**:\n",
        "I will iterate through unrecovered products, extract a product ID prefix, and then search the canonical reference for products within a price tolerance. If a unique match is found, I will update the product information in `products_df` and track the recovery count.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb45f9a3",
        "outputId": "efc6f05c-eab2-4947-e267-92f625cecddb"
      },
      "source": [
        "print(f\"Initial number of unrecovered products before prefix matching: {products_df[~products_df['is_recovered']].shape[0]}\")\n",
        "\n",
        "# Get indices of currently unrecovered products\n",
        "unrecovered_indices = products_df[~products_df['is_recovered']].index\n",
        "\n",
        "num_prefix_matches_recovered = 0\n",
        "\n",
        "# Iterate through unrecovered products\n",
        "for idx in unrecovered_indices:\n",
        "    current_product_id = products_df.loc[idx, 'product_id']\n",
        "    current_unit_price = products_df.loc[idx, 'unit_price']\n",
        "\n",
        "    # Ensure product_id is long enough for a 6-digit prefix\n",
        "    if len(current_product_id) < 6:\n",
        "        continue\n",
        "\n",
        "    prefix = current_product_id[:6]\n",
        "\n",
        "    # Define price tolerance bounds\n",
        "    lower_bound = current_unit_price - 0.01\n",
        "    upper_bound = current_unit_price + 0.01\n",
        "\n",
        "    # Filter canonical_products_df for matches based on prefix and price tolerance\n",
        "    potential_matches = canonical_products_df[\n",
        "        canonical_products_df['product_id'].str.startswith(prefix) &\n",
        "        (canonical_products_df['unit_price'] >= lower_bound) &\n",
        "        (canonical_products_df['unit_price'] <= upper_bound)\n",
        "    ]\n",
        "\n",
        "    # If exactly one match is found, update products_df\n",
        "    if len(potential_matches) == 1:\n",
        "        matched_product_id = potential_matches['product_id'].iloc[0]\n",
        "        products_df.loc[idx, 'recovered_product_id'] = matched_product_id\n",
        "        products_df.loc[idx, 'is_recovered'] = True\n",
        "        num_prefix_matches_recovered += 1\n",
        "\n",
        "print(f\"Number of products recovered by prefix match with price tolerance: {num_prefix_matches_recovered}\")\n",
        "print(f\"Total recovered products after prefix match: {products_df['is_recovered'].sum()}\")\n",
        "print(\"\\nproducts_df head after prefix match recovery:\")\n",
        "print(products_df.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of unrecovered products before prefix matching: 26082\n",
            "Number of products recovered by prefix match with price tolerance: 19308\n",
            "Total recovered products after prefix match: 55926\n",
            "\n",
            "products_df head after prefix match recovery:\n",
            "      product_id                              product_name         Brand  \\\n",
            "0  5281020000000          BEESLINE ELDER ROSE DEO R.ON 50M  BEESLINE DEO   \n",
            "1  5281020000000  BEESLINE GREEN FORST WHIT.R.ON DEOD.50M#  BEESLINE DEO   \n",
            "2  5281020000000    BEESLINE PACIFIC ISLANDS DEO R.ON 50M#  BEESLINE DEO   \n",
            "3  5281020000000         BEESLINE COOL BREEZE DEO R.ON 50M  BEESLINE DEO   \n",
            "4  5281020000000        BEESLINE HR DELAYING DEO R.ON 50M#  BEESLINE DEO   \n",
            "\n",
            "              Division         Category      Subcategory         Segment  \\\n",
            "0  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "1  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "2  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "3  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "4  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "\n",
            "   unit_price recovered_product_id  is_recovered  \n",
            "0       40.58        5281020000000          True  \n",
            "1       95.32        5281020000000          True  \n",
            "2       74.54        5281020000000          True  \n",
            "3       61.87        5281020000000          True  \n",
            "4       19.82        5281020000000          True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "162b0fc1"
      },
      "source": [
        "## Categorize Products and Generate Summary\n",
        "\n",
        "### Subtask:\n",
        "Separate the 'products_dimension' DataFrame into two new DataFrames: one containing products with successfully recovered 'product_id's ('products_dimension_recovered') and another for those that failed recovery ('products_dimension_failed'). Calculate and print summary statistics including: total products in dimension, count of values that needed recovery (initially 'damaged'), number of successfully recovered values, number of values that failed recovery, and the overall recovery success rate percentage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "990da4c3"
      },
      "source": [
        "**Reasoning**:\n",
        "I will create two new DataFrames, `products_dimension_recovered` and `products_dimension_failed`, by filtering the `products_df` based on the `is_recovered` column. Then, I will calculate and print the requested summary statistics to provide an overview of the recovery process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48c4c195",
        "outputId": "51df09bc-92e7-4c27-ebad-46c5e7c24f09"
      },
      "source": [
        "products_dimension_recovered = products_df[products_df['is_recovered']].copy()\n",
        "products_dimension_failed = products_df[~products_df['is_recovered']].copy()\n",
        "\n",
        "total_products_in_dimension = len(products_df)\n",
        "num_successfully_recovered = products_df['is_recovered'].sum()\n",
        "num_failed_recovery = total_products_in_dimension - num_successfully_recovered\n",
        "\n",
        "# Ensure initial_damaged_product_ids is correctly interpreted as needing recovery\n",
        "# It was calculated in a previous step as rows where original product_id != cleaned product_id\n",
        "# which signifies products that needed some form of cleaning/recovery.\n",
        "# The variable `initial_damaged_product_ids` holds this count.\n",
        "\n",
        "recovery_success_rate = (num_successfully_recovered / total_products_in_dimension) * 100 if total_products_in_dimension > 0 else 0\n",
        "\n",
        "print(\"--- Product ID Recovery Summary ---\")\n",
        "print(f\"Total products in products_dimension: {total_products_in_dimension}\")\n",
        "print(f\"Number of values that initially needed recovery (damaged): {initial_damaged_product_ids}\")\n",
        "print(f\"Number of successfully recovered product IDs: {num_successfully_recovered}\")\n",
        "print(f\"Number of product IDs that failed recovery: {num_failed_recovery}\")\n",
        "print(f\"Overall recovery success rate: {recovery_success_rate:.2f}%\")\n",
        "\n",
        "print(\"\\nproducts_dimension_recovered head:\")\n",
        "print(products_dimension_recovered.head())\n",
        "print(\"\\nproducts_dimension_failed head:\")\n",
        "print(products_dimension_failed.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Product ID Recovery Summary ---\n",
            "Total products in products_dimension: 62700\n",
            "Number of values that initially needed recovery (damaged): 26084\n",
            "Number of successfully recovered product IDs: 55926\n",
            "Number of product IDs that failed recovery: 6774\n",
            "Overall recovery success rate: 89.20%\n",
            "\n",
            "products_dimension_recovered head:\n",
            "      product_id                              product_name         Brand  \\\n",
            "0  5281020000000          BEESLINE ELDER ROSE DEO R.ON 50M  BEESLINE DEO   \n",
            "1  5281020000000  BEESLINE GREEN FORST WHIT.R.ON DEOD.50M#  BEESLINE DEO   \n",
            "2  5281020000000    BEESLINE PACIFIC ISLANDS DEO R.ON 50M#  BEESLINE DEO   \n",
            "3  5281020000000         BEESLINE COOL BREEZE DEO R.ON 50M  BEESLINE DEO   \n",
            "4  5281020000000        BEESLINE HR DELAYING DEO R.ON 50M#  BEESLINE DEO   \n",
            "\n",
            "              Division         Category      Subcategory         Segment  \\\n",
            "0  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "1  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "2  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "3  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "4  EVERYDAY ESSENTIALS  BODY FRESHENERS  LADY FRESHENERS  LADY DEODORANT   \n",
            "\n",
            "   unit_price recovered_product_id  is_recovered  \n",
            "0       40.58        5281020000000          True  \n",
            "1       95.32        5281020000000          True  \n",
            "2       74.54        5281020000000          True  \n",
            "3       61.87        5281020000000          True  \n",
            "4       19.82        5281020000000          True  \n",
            "\n",
            "products_dimension_failed head:\n",
            "          product_id                              product_name        Brand  \\\n",
            "36702  6225000000000   VIE VALLEE BATTY HR NOURISH.SERUM 100M#   VIE VALLEE   \n",
            "36707  5900720000000  PHARMACERIS A-IRRITATED&REDDENED CR.30M#  PHARMACERIS   \n",
            "36713     3201865777      VASTASIERO 20MG 20/SCOR.F.C.TAB(NEW)   VASTASIERO   \n",
            "36731  5943080000000            IVATHERM UNA A.AGE EYE CR 15M#     IVATHERM   \n",
            "36755   952115000000  BIOBLAS(A.DAND.SHAMP.360+F.LOOK GEL150@#      BIOBLAS   \n",
            "\n",
            "             Division             Category             Subcategory  \\\n",
            "36702          BEAUTY  MEDICATED HAIR CARE                 STYLING   \n",
            "36707  PREMIUM BEAUTY  MEDICATED SKIN CARE  DRYNESS AND IRRITATION   \n",
            "36713              RX                  CVS          HYPERLIPIDEMIA   \n",
            "36731  PREMIUM BEAUTY  MEDICATED SKIN CARE              ANTI AGING   \n",
            "36755  PREMIUM BEAUTY  MEDICATED HAIR CARE           ANTI DANDRUFF   \n",
            "\n",
            "                        Segment  unit_price recovered_product_id  is_recovered  \n",
            "36702                     SERUM       80.03            6.225E+12         False  \n",
            "36707                FACE CREAM       21.88          5.90072E+12         False  \n",
            "36713  CHOLEST SYNTH INHIBITORS       16.27           3201865777         False  \n",
            "36731                 EYE CREAM       13.34          5.94308E+12         False  \n",
            "36755    WITH SULPHATE SHAMPOOS       38.58          9.52115E+11         False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34d80303"
      },
      "source": [
        "**Reasoning**:\n",
        "I will save the `products_dimension_recovered` DataFrame to a CSV file named 'products_dimension_recovered.csv' and the `products_dimension_failed` DataFrame to 'products_dimension_failed.csv' as required by the overall task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04085760",
        "outputId": "baa377ac-9a2f-4847-cb8c-7fe100222646"
      },
      "source": [
        "products_dimension_recovered.to_csv('products_dimension_recovered.csv', index=False)\n",
        "products_dimension_failed.to_csv('products_dimension_failed.csv', index=False)\n",
        "\n",
        "print(\"'products_dimension_recovered.csv' and 'products_dimension_failed.csv' have been saved.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'products_dimension_recovered.csv' and 'products_dimension_failed.csv' have been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ed0fdd4"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a summary of the data quality process, the number of product IDs successfully recovered, and highlight any remaining unrecovered entries, along with insights into potential further investigation if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb81ea1f"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "*   **Summary of the data quality process:** The data quality process involved several key steps:\n",
        "    1.  **Data Loading and Preparation:** `products_dimension.csv` and `order_products_fact.csv` were loaded, with `product_id` and `unit_price` columns cast to appropriate types. A `recovered_product_id` column and an `is_recovered` flag were initialized in the `products_df`.\n",
        "    2.  **Product ID Cleaning:** The `product_id` column in `products_df` was cleaned by removing trailing '.0', converting scientific notation to standard numeric strings, and eliminating all non-numeric characters. This process identified 26,084 product IDs that initially needed cleaning or recovery.\n",
        "    3.  **Canonical Reference Creation:** A canonical reference DataFrame was created from `order_products_fact.csv` containing unique, cleaned `product_id` and `unit_price` combinations to serve as the authoritative source for lookups.\n",
        "    4.  **Exact Match Recovery:** An initial recovery attempt was made by finding exact matches for cleaned `product_id` and `unit_price` in the canonical reference.\n",
        "    5.  **Prefix Match with Price Tolerance Recovery:** For products not recovered by an exact match, a second recovery attempt was made. This involved using the first 6 digits of the cleaned `product_id` as a prefix and searching the canonical reference for product IDs with this prefix, provided their `unit_price` was within a \\$0.01 tolerance.\n",
        "    6.  **Categorization and Summary:** Finally, products were categorized into successfully recovered and failed recovery groups, and comprehensive statistics were generated.\n",
        "*   **Number of product IDs successfully recovered:** A total of 55,926 product IDs were successfully recovered.\n",
        "*   **Remaining unrecovered entries:** 6,774 product IDs remained unrecovered after the process.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `products_dimension` dataset initially contained 62,700 entries.\n",
        "*   Out of these, 26,084 entries (approximately 41.6% of the total) had `product_id` values that required initial cleaning due to formatting inconsistencies like scientific notation, trailing decimal zeros, or non-numeric characters.\n",
        "*   The exact matching recovery strategy successfully identified and recovered 36,618 product IDs.\n",
        "*   An additional 19,308 product IDs were recovered using the prefix matching with price tolerance strategy.\n",
        "*   Overall, 55,926 product IDs were successfully recovered, leading to a high recovery success rate of 89.20%.\n",
        "*   Despite the extensive recovery efforts, 6,774 product IDs remained unrecovered, indicating persistent data quality issues for these specific entries.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Investigate the 6,774 unrecovered product IDs. This could involve manual review, analyzing common patterns or errors in their original `product_id` and `unit_price` values, or exploring alternative fuzzy matching techniques (e.g., Levenshtein distance) if initial prefixes or prices are too dissimilar.\n",
        "*   Review the initial data entry or generation processes for `products_dimension.csv` to identify root causes of the `product_id` inconsistencies and prevent similar issues in the future.\n"
      ]
    }
  ]
}