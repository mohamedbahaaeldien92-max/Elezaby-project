{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlXzthMPLtywL96CAbw1ei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedbahaaeldien92-max/Elezaby-project/blob/main/cleaned_product_dimension.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elBeYbyddVOo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81c7aa4b"
      },
      "source": [
        "# Task\n",
        "Perform a comprehensive data cleaning, quality assessment, and flagging process on the \"products_dimension.csv\" file. This includes loading the data, profiling, identifying data quality issues (missing values, duplicates, invalid formats, outliers, inconsistent text), standardizing data formats, handling missing values by replacement and flagging original missingness, validating IDs and other data formats, applying business logic validations and flagging issues, detecting and flagging duplicate rows, and finally, generating a cleaned DataFrame along with a detailed data quality report and a 'Before vs After' comparison summary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "064e0f7c"
      },
      "source": [
        "## Load Data and Initial Profiling\n",
        "\n",
        "### Subtask:\n",
        "Load the 'products_dimension.csv' file into a pandas DataFrame named 'df'. Then, perform initial data profiling, which includes displaying the DataFrame's shape, data types of all columns, and summary statistics (e.g., .describe()). This step will also identify numerical versus categorical columns for subsequent cleaning steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1946ecf2"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll import the pandas library to enable data manipulation, then load the 'products_dimension.csv' file into a DataFrame, and display its shape, data types, and descriptive statistics. Afterwards, I will identify and print the numerical and categorical columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb0e9b42",
        "outputId": "cdfb4c2b-64c4-42eb-e215-5c490dc653c7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/products_dimension.csv')\n",
        "\n",
        "# Display the DataFrame's shape\n",
        "print(f\"DataFrame shape: {df.shape}\")\n",
        "\n",
        "# Display data types of all columns\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()\n",
        "\n",
        "# Display descriptive statistics for numerical columns\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Identify numerical and categorical columns\n",
        "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(exclude=np.number).columns.tolist()\n",
        "\n",
        "print(f\"\\nNumerical Columns: {numerical_cols}\")\n",
        "print(f\"Categorical Columns: {categorical_cols}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame shape: (62700, 8)\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 62700 entries, 0 to 62699\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   product_id    62700 non-null  object \n",
            " 1   product_name  62700 non-null  object \n",
            " 2   Brand         59595 non-null  object \n",
            " 3   Division      61877 non-null  object \n",
            " 4   Category      61877 non-null  object \n",
            " 5   Subcategory   61877 non-null  object \n",
            " 6   Segment       61877 non-null  object \n",
            " 7   unit_price    62700 non-null  float64\n",
            "dtypes: float64(1), object(7)\n",
            "memory usage: 3.8+ MB\n",
            "\n",
            "Descriptive Statistics:\n",
            "         unit_price\n",
            "count  62700.000000\n",
            "mean      52.468453\n",
            "std       27.391753\n",
            "min        5.000000\n",
            "25%       28.800000\n",
            "50%       52.500000\n",
            "75%       76.160000\n",
            "max      100.000000\n",
            "\n",
            "Numerical Columns: ['unit_price']\n",
            "Categorical Columns: ['product_id', 'product_name', 'Brand', 'Division', 'Category', 'Subcategory', 'Segment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52953526"
      },
      "source": [
        "## Data Quality Assessment (Identification)\n",
        "\n",
        "### Subtask:\n",
        "Identify and document data quality issues, including missing values, duplicate rows, invalid formats, outliers using the IQR method, and inconsistent text formatting in string columns. No data will be modified in this step, only assessed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd925fae"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll calculate and display the missing values count and percentage for each column in the DataFrame, storing this information in a `missing_data_report` DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae9ff465",
        "outputId": "eea115ec-01eb-45a3-a851-017c27b62d83"
      },
      "source": [
        "missing_count = df.isnull().sum()\n",
        "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
        "\n",
        "missing_data_report = pd.DataFrame({\n",
        "    'Missing Count': missing_count,\n",
        "    'Missing Percentage': missing_percentage\n",
        "})\n",
        "\n",
        "print(\"Missing Data Report:\")\n",
        "print(missing_data_report[missing_data_report['Missing Count'] > 0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Data Report:\n",
            "             Missing Count  Missing Percentage\n",
            "Brand                 3105            4.952153\n",
            "Division               823            1.312600\n",
            "Category               823            1.312600\n",
            "Subcategory            823            1.312600\n",
            "Segment                823            1.312600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "038f7c1f"
      },
      "source": [
        "**Reasoning**:\n",
        "Next, I will detect and report on duplicate rows in the DataFrame by counting them and displaying all identified duplicates for review.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3493d7c7",
        "outputId": "8c00af7d-45ad-43d4-f8b0-395e0f619e31"
      },
      "source": [
        "duplicate_rows = df[df.duplicated(keep=False)]\n",
        "print(f\"Total number of duplicate rows (keeping all occurrences): {len(duplicate_rows)}\")\n",
        "\n",
        "if not duplicate_rows.empty:\n",
        "    print(\"\\nDuplicate Rows (first 50 occurrences):\")\n",
        "    print(duplicate_rows.head(50))\n",
        "else:\n",
        "    print(\"\\nNo duplicate rows found.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of duplicate rows (keeping all occurrences): 0\n",
            "\n",
            "No duplicate rows found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb9986e0"
      },
      "source": [
        "**Reasoning**:\n",
        "I will attempt to convert the 'product_id' column to a numeric type, identifying and displaying any values that cause conversion errors, as these indicate invalid data formats.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a5f03aa",
        "outputId": "3a3f466f-362d-428d-c54d-31d5fd3745ba"
      },
      "source": [
        "invalid_product_ids = df[pd.to_numeric(df['product_id'], errors='coerce').isna() & df['product_id'].notna()]\n",
        "\n",
        "print(f\"Number of rows with invalid 'product_id' format: {len(invalid_product_ids)}\")\n",
        "\n",
        "if not invalid_product_ids.empty:\n",
        "    print(\"\\nRows with invalid 'product_id' format (first 20 occurrences):\")\n",
        "    print(invalid_product_ids.head(20))\n",
        "else:\n",
        "    print(\"\\nNo invalid 'product_id' formats found.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with invalid 'product_id' format: 2\n",
            "\n",
            "Rows with invalid 'product_id' format (first 20 occurrences):\n",
            "      product_id     product_name Brand       Division       Category  \\\n",
            "42809          V     VOUCHER DEMO   NaN  PINK ELEPHANT  PINK ELEPHANT   \n",
            "44062         V1  VOUCHER 0.5 EGP   NaN            AUX            AUX   \n",
            "\n",
            "         Subcategory        Segment  unit_price  \n",
            "42809  PINK ELEPHANT  PINK ELEPHANT       39.92  \n",
            "44062            AUX            AUX       67.18  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83b825a4"
      },
      "source": [
        "**Reasoning**:\n",
        "I will inspect the unique values of categorical columns (excluding 'product_id' which was already checked for format) to identify any potential inconsistent entries or unexpected formats, displaying a sample if there are many unique values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd3efedd",
        "outputId": "ec45d8d8-67b4-48cf-d674-c64a5c12a7ba"
      },
      "source": [
        "print(\"\\nInspecting unique values in categorical columns for inconsistencies:\")\n",
        "for col in categorical_cols:\n",
        "    if col == 'product_id': # Already handled\n",
        "        continue\n",
        "    print(f\"\\nColumn: {col}\")\n",
        "    unique_count = df[col].nunique(dropna=False)\n",
        "    print(f\"Number of unique values (including NaN): {unique_count}\")\n",
        "\n",
        "    # Display unique values or a sample if there are too many\n",
        "    if unique_count < 50:\n",
        "        print(df[col].unique())\n",
        "    else:\n",
        "        print(f\"Top 50 unique values (out of {unique_count}):\\n{df[col].value_counts(dropna=False).head(50).index.tolist()}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inspecting unique values in categorical columns for inconsistencies:\n",
            "\n",
            "Column: product_name\n",
            "Number of unique values (including NaN): 62556\n",
            "Top 50 unique values (out of 62556):\n",
            "['XXX', 'X', '++', 'تى شيرت دليفرى رمادى شتوى7XL', 'SOFTMINA5001PANTYHOSE CCL2AT(XXL)BLACK▓', 'توريد وتركيب عود داكت 2*2', 'سدادة ليجراند', 'NEEDLE BURNER ELECTRIC THERMINATOR▓', 'EAR WASHING SYRING(METAL STAINLESS TY.)▓', 'NEW PHARMA INQUIRY', 'تى شيرت دليفرى رمادى شتوى6XL', 'RESUSCITATOR APPARATUS▓', '0', 'DIAGNOSTIC SET (EAR-NOSE-THROAT) E.N.T▓', '###', 'ISOPTO CARPINE 1% EYE DROP', 'مسدس تسخين', 'حزام', 'DEBORAH 24ORE CARE PERF.(SPF20)FOUND./0#', 'شريط لحام', 'TS JAGUAR STANCE EDT F/M 100ML', 'TS JAGUAR CLASSIC GOLD EDT F/M 100ML', 'TS JAGUAR CLASSIC RED EDT F/M 100ML', '$$', 'XXXX', 'تابنتانيتانتابنت', 'CHICCO SOFT SILICONE SPOON RED 6M+™', 'BIODERMA ATODERM ULTRA NOURISH.CR 200M#', 'سخان كهرباء 20  لتر فريش', 'xxxx', 'ACCU-CHEK PERFORMA 50/STRIP▓', 'حبارة طابعة LASER UP107', 'BACK SUPPORT CUSHION F/BED LE150™▓', 'DEBORAH PERFECT CONCEALER MED.ROSE/03#', 'DEBORAH KAJAL EYE PENCIL /104#', 'CHICCO FUNNY RELAX TEETH RING 6M(2580)', 'LOREAL BROW ARTIST PLUMPER MAS.MED/DARK#', 'DEBORAH KAJAL EYE PENCIL /121#', 'PANNINI MIKI LE79#', 'DEBORAH PERFECT CONCEALER LIGH.BEIGE/01#', 'BABY JUNIOR MYHEART FANTASTIC POTTY', 'B.C CEN RACING CAR REMOTE SERIES /513™', 'SUN CLUB WAVE MAT/37490/BC™#', 'ادبتور شاشة سامسونج', 'MAYBELLINE TOTAL TEMPTATION MASCA.BLACK#', 'DEBORAH TRIO HI-TECH SUPER WET&DRY /03#', 'LOREAL SUPER LINER PE.SLIM INTENS BLACK#', 'NIVEA COOL KICK DEOD.STICK F/M 40M#', 'NIVEA NATURAL FAIRNESS DEO.STICK F/W40M#', 'NIVEA A.PER.PROTECT&CARE DEO.STICK 40ML#']\n",
            "\n",
            "Column: Brand\n",
            "Number of unique values (including NaN): 11852\n",
            "Top 50 unique values (out of 11852):\n",
            "[nan, 'BABY CENTER', 'TESTER', 'AMANDA', 'PINK ELEPHANT', 'BOURJOIS MAKE UP', 'KRYOLAN', 'GIFT', 'MAYBELLINE', 'PRIVATE LABEL', 'WET BRUSH', 'KISS', 'CANPOL', 'DEBORAH', 'CHICCO', 'CHEMICALS', 'JINJA', 'RELAXO', 'ORLY', 'AVENT', 'YOLO', 'LABORATORY', 'JOHNSON BABY', 'ARDELL', 'JASPER', 'TITANIA HAIR CARE', 'RUNWAY', 'TITANIA PERSONAL CARE', 'GILLETTE', 'BIONIKE MAKE UP', 'CYBELE', 'DETTOL', 'SIGVARIS', 'NIVEA DEO', 'DRBROWNS', 'GARNIER', 'NUK', 'BOURJOIS', 'LA ROCHE-POSAY', 'MOBILITY AID', 'NANNINI', 'TRUE', 'REXONA', 'MOVE', 'LOREAL ELVIVE', 'PHILIPS', 'DOVE HAIR CARE', 'BIONIKE', 'ROOFA BEAUTY', 'VICHY']\n",
            "\n",
            "Column: Division\n",
            "Number of unique values (including NaN): 16\n",
            "['EVERYDAY ESSENTIALS' 'RX' 'OTC' 'BEAUTY' 'NUTRACEUTICAL' 'AUX' 'ARCHIVE'\n",
            " 'HIGH VALUE ITEMS' 'HOME HEALTH CARE' 'COSMETICS' 'BABY AND MOM'\n",
            " 'PREMIUM BEAUTY' nan 'PINK ELEPHANT' 'EL EZABY SERVICES' 'TAX']\n",
            "\n",
            "Column: Category\n",
            "Number of unique values (including NaN): 115\n",
            "Top 50 unique values (out of 115):\n",
            "['BABY ACCESSORIES', 'MASS HAIR CARE', 'AUX', 'MEDICATED SKIN CARE', 'MAKEUP', 'BEAUTY TOOLS', 'VITAMIN & SUPPLEMENT', 'BODY FRESHENERS', 'BRACE & SUPPORT', 'CVS', 'MASS SKIN CARE', 'ARCHIVE', 'PAIN & FEVER', 'NAIL POLISH', 'CNS', 'ANTI-INFECTIVE', 'MEDICATED HAIR CARE', 'DIGESTIVE HEALTH', 'DIET & FITNESS', 'SKIN HEALTH', 'ORAL CARE', 'CHILDREN HEALTH CARE', 'BATH & BODY', 'FRAGRANCES', nan, 'HYGENIC AND HOUSEHOLD PRODUCTS', 'OPTICAL CARE', 'FIRST AID', 'LADY CARE', 'CONSUMABLES', 'COUGH & COLD', 'SEXUAL HEALTH', 'DIABETES MELLITUS', 'BABY TOILETRIES', 'BABY NAPPIES AND WIPES', 'PINK ELEPHANT', 'KIDS TOILETRIES', 'HORMONE', 'VITAMIN & SUPPLEMENT- SP. IMP.', 'PERSONAL CARE APPLIANCES', 'ANTI CANCER', 'PEDIATRICS', 'EYE DISORDER', 'DIABETES CARE', 'MEN CARE', 'ASTHMA', 'CRITICAL CARE MEDICINE', 'WOMEN HEALTH', 'BABY FOOD', 'BABY MILK']\n",
            "\n",
            "Column: Subcategory\n",
            "Number of unique values (including NaN): 316\n",
            "Top 50 unique values (out of 316):\n",
            "['AUX', 'DRYNESS AND IRRITATION', 'ARCHIVE', 'COLOURING NAIL POLISH', 'LADY FRESHENERS', 'PLAY TIME', 'STYLING', 'FACE', 'BACTERIAL INFECTION', 'HAIR TOOLS', 'LIP', 'SUN CARE', 'DAILY USE', 'ANTI HAIR LOSS & THINNING & GROWTH', 'HEALTH PURPOSE', 'HYPERTENSION', nan, 'WHITENING', 'BATH & SHOWER', 'BOTTLE FEEDING', 'HAND TOOLS', 'MEN FRESHENERS', 'ANALGESICS NSAIDS', 'PREMIUM', 'HAIR REPAIR', 'COLORING', 'HEART BURN & ANTACID', 'EYE', 'GLASSES', 'HEALTHY KID SUPPLEME', 'ANTI AGING', 'FOOT & LEG SUPPORT', 'ARM & SHOULDER SUPPO', 'DM-NON HORMONAL', 'ACNE CARE', 'SKIN CARE', 'PINK ELEPHANT', 'PACIFIERS', 'MINERALS', 'EPILEPSY', 'CLEANSERS AND EXFOLI', 'VITAMIN A Z', 'BODY & POSTURE SUPPO', 'EYE TOOLS', 'HOT & COLD THERAPIES', 'TOOTHPASTE', 'NUTRITIONAL SUPPLEME', 'WOMEN SANITARY CARE', 'HYPERLIPIDEMIA', 'WOUND CARE']\n",
            "\n",
            "Column: Segment\n",
            "Number of unique values (including NaN): 1211\n",
            "Top 50 unique values (out of 1211):\n",
            "['AUX', 'ARCHIVE', 'WITH SULPHATE SHAMPOOS', 'METALLIC', 'TOYS', 'FACE CREAM', 'LADY DEODORANT', nan, 'FOUNDATION', 'LIPSTICK', 'MEN DEODORANT', 'PINK ELEPHANT', \"WOMEN'S FRAGRANCES\", 'READING GLASSES', 'LADY BODY SPLASH', 'ANALGESIC ORAL', 'CONDITIONERS', 'ACID SYNTHESIS INHIBTOR (PPIS)', \"MEN'S FRAGRANCES\", 'FACE CLEANSER', 'PERMANENT  WITH AMMONIA', 'FEEDING BOTTLE', 'CREAM', 'FACE SERUM', 'GENERALIZED AND PARTIAL EPILEPSY', 'ATYPICAL ANTI PSYCH ( NEW GENERATION)', 'FALSE NAILS', 'BODY WASH', 'ADULT TOOTHPASTE', 'FALSE EYELASHES', 'GEL', 'BODY CREAM', 'REGULAR HAIR BRUSH', 'OIL', 'SUN SCREEN LOTION', 'MASKS', 'DETANGLE HAIR BRUSH', 'MASSAGE CREAM & GEL', 'SILICONE', 'SANITARY PADS', 'BODY LOTION', 'ARBS', 'MOISTURIZERS & EMOLIENTS', 'CHOLEST SYNTH INHIBITORS', 'SULPHATE FREE SHAMPOOS', 'LOTION', 'ANTI BIOTIC FLOUROQUINOLONE', 'SOAP BARS', 'COMBINATION', 'BEACH ACCESSORIES']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b0d3ee7"
      },
      "source": [
        "**Reasoning**:\n",
        "Next, I will detect outliers in the 'unit_price' column using the Interquartile Range (IQR) method by calculating Q1, Q3, and IQR, and then determining the lower and upper bounds to identify and count outliers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc5d8547",
        "outputId": "df3cad7c-dbd1-4358-cdc5-671681ea5a14"
      },
      "source": [
        "Q1 = df['unit_price'].quantile(0.25)\n",
        "Q3 = df['unit_price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df[(df['unit_price'] < lower_bound) | (df['unit_price'] > upper_bound)]\n",
        "\n",
        "print(f\"\\nNumber of outliers in 'unit_price' using IQR method: {len(outliers)}\")\n",
        "if not outliers.empty:\n",
        "    print(\"Outliers in 'unit_price' (first 20 occurrences):\")\n",
        "    print(outliers.head(20))\n",
        "else:\n",
        "    print(\"No outliers found in 'unit_price'.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of outliers in 'unit_price' using IQR method: 0\n",
            "No outliers found in 'unit_price'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "012f5028"
      },
      "source": [
        "**Reasoning**:\n",
        "I will examine the categorical columns for inconsistent text formatting by comparing the number of unique values before and after applying `.str.strip().str.lower()`, which will highlight variations due to casing or leading/trailing spaces.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a289ad5",
        "outputId": "7ae59e39-e90a-4f13-fbea-1a4e0c8254d3"
      },
      "source": [
        "print(\"\\nInspecting categorical columns for inconsistent text formatting (casing, leading/trailing spaces):\")\n",
        "for col in categorical_cols:\n",
        "    if col in ['product_id', 'product_name']: # product_id already checked, product_name has too many unique values to be practical for this check\n",
        "        continue\n",
        "\n",
        "    original_unique_count = df[col].nunique(dropna=False)\n",
        "\n",
        "    # Apply strip and lower, then count unique values (excluding NaN for this comparison)\n",
        "    processed_unique_count = df[col].astype(str).str.strip().str.lower().nunique(dropna=False)\n",
        "\n",
        "    if original_unique_count != processed_unique_count:\n",
        "        print(f\"Column '{col}': Inconsistent formatting detected (Original unique: {original_unique_count}, Processed unique: {processed_unique_count})\")\n",
        "        # Optionally print some examples if needed, but for now, just count is sufficient\n",
        "    else:\n",
        "        print(f\"Column '{col}': No significant text formatting inconsistencies found (Unique values count: {original_unique_count})\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inspecting categorical columns for inconsistent text formatting (casing, leading/trailing spaces):\n",
            "Column 'Brand': Inconsistent formatting detected (Original unique: 11852, Processed unique: 11848)\n",
            "Column 'Division': No significant text formatting inconsistencies found (Unique values count: 16)\n",
            "Column 'Category': No significant text formatting inconsistencies found (Unique values count: 115)\n",
            "Column 'Subcategory': No significant text formatting inconsistencies found (Unique values count: 316)\n",
            "Column 'Segment': No significant text formatting inconsistencies found (Unique values count: 1211)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2344b90d"
      },
      "source": [
        "## Standardize Data Formats\n",
        "\n",
        "### Subtask:\n",
        "Clean and standardize various data formats. This includes converting all column names to snake_case, trimming leading and trailing spaces from string columns, and standardizing text casing (e.g., to lowercase or title case) where appropriate. Convert columns to their correct inferred data types based on their content, handling errors by coercing to NaN where necessary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dfbc45b"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll convert all column names to snake_case to ensure consistency and ease of use in subsequent operations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdeed074",
        "outputId": "f72e96f8-15db-4ad9-adc4-95f58e96e98f"
      },
      "source": [
        "import re\n",
        "\n",
        "def to_snake_case(name):\n",
        "    name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
        "    name = re.sub('__([A-Z])', r'_\\1', name)\n",
        "    name = re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', name).lower()\n",
        "    return name\n",
        "\n",
        "df.columns = [to_snake_case(col) for col in df.columns]\n",
        "\n",
        "print(\"Columns after converting to snake_case:\")\n",
        "print(df.columns.tolist())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns after converting to snake_case:\n",
            "['product_id', 'product_name', 'brand', 'division', 'category', 'subcategory', 'segment', 'unit_price']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7f26720"
      },
      "source": [
        "**Reasoning**:\n",
        "Next, I will iterate through all object (string) columns to remove leading/trailing whitespace and then apply appropriate casing (title case for descriptive columns, lowercase for 'product_name').\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66241024",
        "outputId": "acf3e610-57ba-46f2-9afa-8fb3f9395f1c"
      },
      "source": [
        "for col in df.select_dtypes(include='object').columns:\n",
        "    # Strip whitespace from all object columns\n",
        "    df[col] = df[col].str.strip()\n",
        "\n",
        "    # Apply specific casing\n",
        "    if col in ['brand', 'division', 'category', 'subcategory', 'segment']:\n",
        "        df[col] = df[col].str.title()\n",
        "    elif col == 'product_name':\n",
        "        df[col] = df[col].str.lower()\n",
        "\n",
        "print(\"String columns after stripping whitespace and applying casing (first 5 rows):\")\n",
        "print(df.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "String columns after stripping whitespace and applying casing (first 5 rows):\n",
            "    product_id                              product_name         brand  \\\n",
            "0  5.28102E+12          beesline elder rose deo r.on 50m  Beesline Deo   \n",
            "1  5.28102E+12  beesline green forst whit.r.on deod.50m#  Beesline Deo   \n",
            "2  5.28102E+12    beesline pacific islands deo r.on 50m#  Beesline Deo   \n",
            "3  5.28102E+12         beesline cool breeze deo r.on 50m  Beesline Deo   \n",
            "4  5.28102E+12        beesline hr delaying deo r.on 50m#  Beesline Deo   \n",
            "\n",
            "              division         category      subcategory         segment  \\\n",
            "0  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "1  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "2  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "3  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "4  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "\n",
            "   unit_price  \n",
            "0       40.58  \n",
            "1       95.32  \n",
            "2       74.54  \n",
            "3       61.87  \n",
            "4       19.82  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bba95ffa"
      },
      "source": [
        "**Reasoning**:\n",
        "I will infer and convert data types for all columns using `df.convert_dtypes()` to optimize memory and type representation. Then, I'll explicitly convert the 'product_id' column to a numeric type, coercing any non-numeric values to NaN, and create a new boolean flag column, 'is_invalid_product_id_format', to mark rows where this conversion failed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b69e10c0",
        "outputId": "904ea542-726d-4b34-bb70-f0ecc702a7a1"
      },
      "source": [
        "df_original = df.copy()\n",
        "# Infer and convert data types for all columns\n",
        "df = df.convert_dtypes()\n",
        "\n",
        "# Convert 'product_id' to numeric, coercing errors to NaN\n",
        "df['product_id_numeric'] = pd.to_numeric(df['product_id'], errors='coerce')\n",
        "\n",
        "# Create a flag for invalid 'product_id' formats\n",
        "df['is_invalid_product_id_format'] = df['product_id_numeric'].isna() & df['product_id'].notna()\n",
        "\n",
        "# Display the DataFrame info after type conversion and the first few rows with the new columns\n",
        "print(\"\\nDataFrame Info after type conversion and flagging:\")\n",
        "df.info()\n",
        "print(\"\\nDataFrame head with new 'product_id_numeric' and 'is_invalid_product_id_format' columns:\")\n",
        "print(df.head())\n",
        "\n",
        "print(f\"\\nNumber of rows flagged with invalid product_id format: {df['is_invalid_product_id_format'].sum()}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame Info after type conversion and flagging:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 62700 entries, 0 to 62699\n",
            "Data columns (total 10 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   product_id                    62700 non-null  string \n",
            " 1   product_name                  62700 non-null  string \n",
            " 2   brand                         59595 non-null  string \n",
            " 3   division                      61877 non-null  string \n",
            " 4   category                      61877 non-null  string \n",
            " 5   subcategory                   61877 non-null  string \n",
            " 6   segment                       61877 non-null  string \n",
            " 7   unit_price                    62700 non-null  Float64\n",
            " 8   product_id_numeric            62698 non-null  Float64\n",
            " 9   is_invalid_product_id_format  62700 non-null  bool   \n",
            "dtypes: Float64(2), bool(1), string(7)\n",
            "memory usage: 4.5 MB\n",
            "\n",
            "DataFrame head with new 'product_id_numeric' and 'is_invalid_product_id_format' columns:\n",
            "    product_id                              product_name         brand  \\\n",
            "0  5.28102E+12          beesline elder rose deo r.on 50m  Beesline Deo   \n",
            "1  5.28102E+12  beesline green forst whit.r.on deod.50m#  Beesline Deo   \n",
            "2  5.28102E+12    beesline pacific islands deo r.on 50m#  Beesline Deo   \n",
            "3  5.28102E+12         beesline cool breeze deo r.on 50m  Beesline Deo   \n",
            "4  5.28102E+12        beesline hr delaying deo r.on 50m#  Beesline Deo   \n",
            "\n",
            "              division         category      subcategory         segment  \\\n",
            "0  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "1  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "2  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "3  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "4  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "\n",
            "   unit_price  product_id_numeric  is_invalid_product_id_format  \n",
            "0       40.58     5281020000000.0                         False  \n",
            "1       95.32     5281020000000.0                         False  \n",
            "2       74.54     5281020000000.0                         False  \n",
            "3       61.87     5281020000000.0                         False  \n",
            "4       19.82     5281020000000.0                         False  \n",
            "\n",
            "Number of rows flagged with invalid product_id format: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe967d77"
      },
      "source": [
        "## Handle Missing Values and Flag `is_missing_original`\n",
        "\n",
        "### Subtask:\n",
        "Address missing values without deleting rows. For numerical columns, replace missing values with the column's median. For categorical columns, replace missing values with the string 'unknown'. For each column that had original missing values, create a new boolean flag column named `is_missing_original_{column_name}` to indicate where values were originally missing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d4d9495"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll identify columns with missing values and create a new boolean flag column for each to indicate where values were originally missing. Then, I will fill the missing values in these categorical columns with the string 'Unknown'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "561b99e7",
        "outputId": "de750ce9-e297-4dee-9070-3486eb026257"
      },
      "source": [
        "missing_cols = df.columns[df.isnull().any()].tolist()\n",
        "\n",
        "for col in missing_cols:\n",
        "    # Create a flag column for original missingness\n",
        "    df[f'is_missing_original_{col}'] = df[col].isnull()\n",
        "\n",
        "    # Handle categorical columns by filling with 'Unknown'\n",
        "    if df[col].dtype == 'string': # Check for pandas StringDtype\n",
        "        df[col] = df[col].fillna('Unknown')\n",
        "    # Assuming numerical columns (if any) would be handled here, but for this dataset, only categorical have missing values.\n",
        "    # If there were numerical columns with missing values, the logic would be:\n",
        "    # elif pd.api.types.is_numeric_dtype(df[col]):\n",
        "    #     median_val = df[col].median()\n",
        "    #     df[col] = df[col].fillna(median_val)\n",
        "\n",
        "print(\"Missing values handled and flag columns created.\")\n",
        "print(\"New flag columns and their sum of True values:\")\n",
        "for col in missing_cols:\n",
        "    print(f\"is_missing_original_{col}: {df[f'is_missing_original_{col}'].sum()} True values\")\n",
        "\n",
        "print(\"\\nVerifying no remaining missing values:\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values handled and flag columns created.\n",
            "New flag columns and their sum of True values:\n",
            "is_missing_original_brand: 3105 True values\n",
            "is_missing_original_division: 823 True values\n",
            "is_missing_original_category: 823 True values\n",
            "is_missing_original_subcategory: 823 True values\n",
            "is_missing_original_segment: 823 True values\n",
            "is_missing_original_product_id_numeric: 2 True values\n",
            "\n",
            "Verifying no remaining missing values:\n",
            "product_id                                0\n",
            "product_name                              0\n",
            "brand                                     0\n",
            "division                                  0\n",
            "category                                  0\n",
            "subcategory                               0\n",
            "segment                                   0\n",
            "unit_price                                0\n",
            "product_id_numeric                        2\n",
            "is_invalid_product_id_format              0\n",
            "is_missing_original_brand                 0\n",
            "is_missing_original_division              0\n",
            "is_missing_original_category              0\n",
            "is_missing_original_subcategory           0\n",
            "is_missing_original_segment               0\n",
            "is_missing_original_product_id_numeric    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6e8294a"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step identified that 'product_id_numeric' still has missing values, which is a numerical column. Following the subtask's instruction, I will fill these missing values with the column's median.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec32a200",
        "outputId": "8c0edb9a-f8ed-4b5c-848d-b5fad2cad330"
      },
      "source": [
        "if 'product_id_numeric' in df.columns and df['product_id_numeric'].isnull().any():\n",
        "    median_product_id_numeric = df['product_id_numeric'].median()\n",
        "    df['product_id_numeric'] = df['product_id_numeric'].fillna(median_product_id_numeric)\n",
        "    print(f\"Missing values in 'product_id_numeric' filled with median: {median_product_id_numeric}\")\n",
        "\n",
        "print(\"\\nVerifying no remaining missing values after numerical imputation:\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in 'product_id_numeric' filled with median: 3012287777.0\n",
            "\n",
            "Verifying no remaining missing values after numerical imputation:\n",
            "product_id                                0\n",
            "product_name                              0\n",
            "brand                                     0\n",
            "division                                  0\n",
            "category                                  0\n",
            "subcategory                               0\n",
            "segment                                   0\n",
            "unit_price                                0\n",
            "product_id_numeric                        0\n",
            "is_invalid_product_id_format              0\n",
            "is_missing_original_brand                 0\n",
            "is_missing_original_division              0\n",
            "is_missing_original_category              0\n",
            "is_missing_original_subcategory           0\n",
            "is_missing_original_segment               0\n",
            "is_missing_original_product_id_numeric    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b17c424b"
      },
      "source": [
        "## Validate IDs and Flag `is_corrupted_id` and `is_invalid_format`\n",
        "\n",
        "### Subtask:\n",
        "Apply specific ID validation rules for 'product_id'. Create a new boolean column `is_corrupted_id` to flag rows where 'product_id' fails these validations (non-numeric, not 13-digit integer). Additionally, create a general `is_invalid_format` flag column to mark any other invalid formats, using the previously created `is_invalid_product_id_format` for now.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f7ae733"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will initialize the `is_corrupted_id` column to `False` and populate it based on existing `is_invalid_product_id_format` flags. Then, I'll convert valid `product_id_numeric` values to integer strings to check if their length is exactly 13 digits, updating `is_corrupted_id` accordingly. Finally, I will create the `is_invalid_format` column and print the counts for the new flag columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10e846ca",
        "outputId": "1480a9a3-f7df-44a6-c0e4-a2c54e6302cf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Create a new boolean column named is_corrupted_id initialized to False.\n",
        "df['is_corrupted_id'] = False\n",
        "\n",
        "# 2. Update is_corrupted_id to True for any rows where the is_invalid_product_id_format\n",
        "#    flag is already True (indicating original non-numeric product_id values).\n",
        "df.loc[df['is_invalid_product_id_format'], 'is_corrupted_id'] = True\n",
        "\n",
        "# 3. For rows where is_corrupted_id is still False, check if the product_id_numeric\n",
        "#    (converted to a string representation of an integer) does not have a length of 13.\n",
        "#    If it does not, set is_corrupted_id to True for those rows.\n",
        "\n",
        "# For rows not yet flagged as corrupted, check the length of the numeric ID\n",
        "not_corrupted_yet_mask = ~df['is_corrupted_id']\n",
        "\n",
        "# Convert product_id_numeric to integer string for length check\n",
        "# Handle potential NaN values by converting to empty string or a placeholder first, though it should be filled already.\n",
        "# Since `product_id_numeric` is Float64, we need to convert it to an integer first before casting to string\n",
        "# to avoid decimal points (e.g., '123.0' vs '123').\n",
        "# Using .astype('Int64') to handle nullable integers if any before converting to string\n",
        "df.loc[not_corrupted_yet_mask, 'product_id_str_for_len_check'] = df.loc[not_corrupted_yet_mask, 'product_id_numeric'].astype('Int64').astype(str)\n",
        "\n",
        "# Apply the length check\n",
        "df.loc[not_corrupted_yet_mask & (df['product_id_str_for_len_check'].str.len() != 13), 'is_corrupted_id'] = True\n",
        "\n",
        "# Drop the temporary column\n",
        "df = df.drop(columns=['product_id_str_for_len_check'], errors='ignore')\n",
        "\n",
        "# 4. Create a new boolean column named is_invalid_format and assign the values\n",
        "#    from the existing is_invalid_product_id_format column to it.\n",
        "df['is_invalid_format'] = df['is_invalid_product_id_format']\n",
        "\n",
        "# 5. Print the sum of True values for both is_corrupted_id and is_invalid_format.\n",
        "print(f\"Number of rows flagged as 'is_corrupted_id': {df['is_corrupted_id'].sum()}\")\n",
        "print(f\"Number of rows flagged as 'is_invalid_format': {df['is_invalid_format'].sum()}\")\n",
        "\n",
        "print(\"\\nDataFrame head with new flag columns:\")\n",
        "print(df.head())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows flagged as 'is_corrupted_id': 39547\n",
            "Number of rows flagged as 'is_invalid_format': 2\n",
            "\n",
            "DataFrame head with new flag columns:\n",
            "    product_id                              product_name         brand  \\\n",
            "0  5.28102E+12          beesline elder rose deo r.on 50m  Beesline Deo   \n",
            "1  5.28102E+12  beesline green forst whit.r.on deod.50m#  Beesline Deo   \n",
            "2  5.28102E+12    beesline pacific islands deo r.on 50m#  Beesline Deo   \n",
            "3  5.28102E+12         beesline cool breeze deo r.on 50m  Beesline Deo   \n",
            "4  5.28102E+12        beesline hr delaying deo r.on 50m#  Beesline Deo   \n",
            "\n",
            "              division         category      subcategory         segment  \\\n",
            "0  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "1  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "2  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "3  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "4  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "\n",
            "   unit_price  product_id_numeric  is_invalid_product_id_format  \\\n",
            "0       40.58     5281020000000.0                         False   \n",
            "1       95.32     5281020000000.0                         False   \n",
            "2       74.54     5281020000000.0                         False   \n",
            "3       61.87     5281020000000.0                         False   \n",
            "4       19.82     5281020000000.0                         False   \n",
            "\n",
            "   is_missing_original_brand  is_missing_original_division  \\\n",
            "0                      False                         False   \n",
            "1                      False                         False   \n",
            "2                      False                         False   \n",
            "3                      False                         False   \n",
            "4                      False                         False   \n",
            "\n",
            "   is_missing_original_category  is_missing_original_subcategory  \\\n",
            "0                         False                            False   \n",
            "1                         False                            False   \n",
            "2                         False                            False   \n",
            "3                         False                            False   \n",
            "4                         False                            False   \n",
            "\n",
            "   is_missing_original_segment  is_missing_original_product_id_numeric  \\\n",
            "0                        False                                   False   \n",
            "1                        False                                   False   \n",
            "2                        False                                   False   \n",
            "3                        False                                   False   \n",
            "4                        False                                   False   \n",
            "\n",
            "   is_corrupted_id  is_invalid_format  \n",
            "0            False              False  \n",
            "1            False              False  \n",
            "2            False              False  \n",
            "3            False              False  \n",
            "4            False              False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ae082e0"
      },
      "source": [
        "## Business Logic Validation and Flag `is_outlier`\n",
        "\n",
        "### Subtask:\n",
        "Perform business logic validations on the numerical columns and create an `is_outlier` flag based on IQR. Finally, combine all critical flags into a `validation_flag`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "359f6ec7"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will create a new boolean column `is_negative_unit_price` to flag any rows where `unit_price` is negative. Then, I will calculate the IQR, lower, and upper bounds for the `unit_price` column to identify outliers and create an `is_outlier` flag.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ad2eff6",
        "outputId": "7dd76d20-e25b-4484-9807-9bf9a582ca10"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Create a new boolean column named is_negative_unit_price\n",
        "df['is_negative_unit_price'] = df['unit_price'] < 0\n",
        "\n",
        "# 2. Calculate Q1, Q3, and IQR for unit_price\n",
        "Q1 = df['unit_price'].quantile(0.25)\n",
        "Q3 = df['unit_price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# 3. Determine lower and upper bounds for outlier detection\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# 4. Create a new boolean column named is_outlier\n",
        "df['is_outlier'] = (df['unit_price'] < lower_bound) | (df['unit_price'] > upper_bound)\n",
        "\n",
        "print(f\"Number of rows with negative unit_price: {df['is_negative_unit_price'].sum()}\")\n",
        "print(f\"Number of rows identified as outliers in unit_price: {df['is_outlier'].sum()}\")\n",
        "\n",
        "print(\"\\nDataFrame head with new flags:\")\n",
        "print(df[['unit_price', 'is_negative_unit_price', 'is_outlier']].head())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with negative unit_price: 0\n",
            "Number of rows identified as outliers in unit_price: 0\n",
            "\n",
            "DataFrame head with new flags:\n",
            "   unit_price  is_negative_unit_price  is_outlier\n",
            "0       40.58                   False       False\n",
            "1       95.32                   False       False\n",
            "2       74.54                   False       False\n",
            "3       61.87                   False       False\n",
            "4       19.82                   False       False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dace2d9e"
      },
      "source": [
        "**Reasoning**:\n",
        "Next, I will initialize the `validation_flag` column to `False` and then update it to `True` for any rows where `is_corrupted_id`, `is_invalid_format`, `is_negative_unit_price`, or `is_outlier` are `True`, finally printing the sum of `True` values for the new flag and the previously created flags.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d9cf3f7",
        "outputId": "279e67d0-4b21-4e31-b088-c81e96e63ff7"
      },
      "source": [
        "df['validation_flag'] = False\n",
        "df.loc[df['is_corrupted_id'] | \\\n",
        "       df['is_invalid_format'] | \\\n",
        "       df['is_negative_unit_price'] | \\\n",
        "       df['is_outlier'], 'validation_flag'] = True\n",
        "\n",
        "print(f\"\\nNumber of rows with negative unit_price: {df['is_negative_unit_price'].sum()}\")\n",
        "print(f\"Number of rows identified as outliers in unit_price: {df['is_outlier'].sum()}\")\n",
        "print(f\"Total number of rows flagged by 'validation_flag': {df['validation_flag'].sum()}\")\n",
        "\n",
        "print(\"\\nDataFrame head with all validation flags:\")\n",
        "print(df[['product_id', 'unit_price', 'is_corrupted_id', 'is_invalid_format', 'is_negative_unit_price', 'is_outlier', 'validation_flag']].head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of rows with negative unit_price: 0\n",
            "Number of rows identified as outliers in unit_price: 0\n",
            "Total number of rows flagged by 'validation_flag': 39547\n",
            "\n",
            "DataFrame head with all validation flags:\n",
            "    product_id  unit_price  is_corrupted_id  is_invalid_format  \\\n",
            "0  5.28102E+12       40.58            False              False   \n",
            "1  5.28102E+12       95.32            False              False   \n",
            "2  5.28102E+12       74.54            False              False   \n",
            "3  5.28102E+12       61.87            False              False   \n",
            "4  5.28102E+12       19.82            False              False   \n",
            "\n",
            "   is_negative_unit_price  is_outlier  validation_flag  \n",
            "0                   False       False            False  \n",
            "1                   False       False            False  \n",
            "2                   False       False            False  \n",
            "3                   False       False            False  \n",
            "4                   False       False            False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cce889c"
      },
      "source": [
        "## Detect and Flag Duplicates (is_duplicate)\n",
        "\n",
        "### Subtask:\n",
        "Identify duplicate rows within the DataFrame and add a new boolean column, `is_duplicate`, to flag all occurrences of these duplicate rows. Duplicate rows will be flagged but not removed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee4566e9"
      },
      "source": [
        "**Reasoning**:\n",
        "I will create a new boolean column 'is_duplicate' by using `df.duplicated(keep=False)` to flag all occurrences of duplicate rows as True, then print the total number of flagged duplicates and display the DataFrame's head with the new column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f51e3475",
        "outputId": "2b7b4abf-82bc-41cd-8e03-b4caf7832991"
      },
      "source": [
        "df['is_duplicate'] = df.duplicated(keep=False)\n",
        "\n",
        "print(f\"Total number of rows flagged as 'is_duplicate': {df['is_duplicate'].sum()}\")\n",
        "\n",
        "print(\"\\nDataFrame head with new 'is_duplicate' column:\")\n",
        "print(df.head())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows flagged as 'is_duplicate': 0\n",
            "\n",
            "DataFrame head with new 'is_duplicate' column:\n",
            "    product_id                              product_name         brand  \\\n",
            "0  5.28102E+12          beesline elder rose deo r.on 50m  Beesline Deo   \n",
            "1  5.28102E+12  beesline green forst whit.r.on deod.50m#  Beesline Deo   \n",
            "2  5.28102E+12    beesline pacific islands deo r.on 50m#  Beesline Deo   \n",
            "3  5.28102E+12         beesline cool breeze deo r.on 50m  Beesline Deo   \n",
            "4  5.28102E+12        beesline hr delaying deo r.on 50m#  Beesline Deo   \n",
            "\n",
            "              division         category      subcategory         segment  \\\n",
            "0  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "1  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "2  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "3  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "4  Everyday Essentials  Body Fresheners  Lady Fresheners  Lady Deodorant   \n",
            "\n",
            "   unit_price  product_id_numeric  is_invalid_product_id_format  ...  \\\n",
            "0       40.58     5281020000000.0                         False  ...   \n",
            "1       95.32     5281020000000.0                         False  ...   \n",
            "2       74.54     5281020000000.0                         False  ...   \n",
            "3       61.87     5281020000000.0                         False  ...   \n",
            "4       19.82     5281020000000.0                         False  ...   \n",
            "\n",
            "   is_missing_original_category  is_missing_original_subcategory  \\\n",
            "0                         False                            False   \n",
            "1                         False                            False   \n",
            "2                         False                            False   \n",
            "3                         False                            False   \n",
            "4                         False                            False   \n",
            "\n",
            "   is_missing_original_segment  is_missing_original_product_id_numeric  \\\n",
            "0                        False                                   False   \n",
            "1                        False                                   False   \n",
            "2                        False                                   False   \n",
            "3                        False                                   False   \n",
            "4                        False                                   False   \n",
            "\n",
            "   is_corrupted_id  is_invalid_format  is_negative_unit_price  is_outlier  \\\n",
            "0            False              False                   False       False   \n",
            "1            False              False                   False       False   \n",
            "2            False              False                   False       False   \n",
            "3            False              False                   False       False   \n",
            "4            False              False                   False       False   \n",
            "\n",
            "   validation_flag  is_duplicate  \n",
            "0            False         False  \n",
            "1            False         False  \n",
            "2            False         False  \n",
            "3            False         False  \n",
            "4            False         False  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baf05aeb"
      },
      "source": [
        "## Generate Final Output and Report\n",
        "\n",
        "### Subtask:\n",
        "Construct the final cleaned DataFrame (`cleaned_df`), generate a comprehensive data quality report (`data_quality_report`), and create a 'Before vs After' comparison summary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe371eed"
      },
      "source": [
        "**Reasoning**:\n",
        "I will create a copy of the current DataFrame `df` and name it `cleaned_df` to represent the final cleaned dataset. Then, I will initialize an empty dictionary `data_quality_report` to store the data quality metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e22f9b9a",
        "outputId": "9cfc1cbd-9bc5-4b1f-fe0a-ff53c2a8163c"
      },
      "source": [
        "cleaned_df = df.copy()\n",
        "\n",
        "data_quality_report = {}\n",
        "\n",
        "print(\"Created cleaned_df and initialized data_quality_report.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created cleaned_df and initialized data_quality_report.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe252ab4"
      },
      "source": [
        "**Reasoning**:\n",
        "I will populate the `data_quality_report` dictionary with the 'Overall Data Quality Summary' by calculating the total number of rows, the total number of rows flagged by `validation_flag`, and the percentage of flagged rows. Then, I will iterate through all columns with `is_missing_original_` prefix and populate the 'Missing Values (Original)' section with their respective counts and percentages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b11167c",
        "outputId": "a64676c9-46f3-464d-de0d-19ccd42e6244"
      },
      "source": [
        "total_rows = cleaned_df.shape[0]\n",
        "\n",
        "# Overall Data Quality Summary\n",
        "data_quality_report['Overall Data Quality Summary'] = {\n",
        "    'Total Rows': total_rows,\n",
        "    'Total Flagged Rows (validation_flag)': cleaned_df['validation_flag'].sum(),\n",
        "    'Percentage Flagged Rows': (cleaned_df['validation_flag'].sum() / total_rows) * 100\n",
        "}\n",
        "\n",
        "# Missing Values (Original)\n",
        "data_quality_report['Missing Values (Original)'] = {}\n",
        "original_missing_cols = [col for col in cleaned_df.columns if col.startswith('is_missing_original_')]\n",
        "for col in original_missing_cols:\n",
        "    count = cleaned_df[col].sum()\n",
        "    percentage = (count / total_rows) * 100\n",
        "    data_quality_report['Missing Values (Original)'][col] = {\n",
        "        'Count': count,\n",
        "        'Percentage': percentage\n",
        "    }\n",
        "\n",
        "# Invalid Formats\n",
        "invalid_format_count = cleaned_df['is_invalid_format'].sum()\n",
        "invalid_format_percentage = (invalid_format_count / total_rows) * 100\n",
        "data_quality_report['Invalid Formats'] = {\n",
        "    'Count': invalid_format_count,\n",
        "    'Percentage': invalid_format_percentage\n",
        "}\n",
        "\n",
        "# Corrupted IDs\n",
        "corrupted_id_count = cleaned_df['is_corrupted_id'].sum()\n",
        "corrupted_id_percentage = (corrupted_id_count / total_rows) * 100\n",
        "data_quality_report['Corrupted IDs'] = {\n",
        "    'Count': corrupted_id_count,\n",
        "    'Percentage': corrupted_id_percentage\n",
        "}\n",
        "\n",
        "# Outliers\n",
        "outlier_count = cleaned_df['is_outlier'].sum()\n",
        "outlier_percentage = (outlier_count / total_rows) * 100\n",
        "data_quality_report['Outliers'] = {\n",
        "    'Count': outlier_count,\n",
        "    'Percentage': outlier_percentage\n",
        "}\n",
        "\n",
        "# Negative Unit Price\n",
        "negative_unit_price_count = cleaned_df['is_negative_unit_price'].sum()\n",
        "negative_unit_price_percentage = (negative_unit_price_count / total_rows) * 100\n",
        "data_quality_report['Negative Unit Price'] = {\n",
        "    'Count': negative_unit_price_count,\n",
        "    'Percentage': negative_unit_price_percentage\n",
        "}\n",
        "\n",
        "# Duplicates\n",
        "duplicate_count = cleaned_df['is_duplicate'].sum()\n",
        "duplicate_percentage = (duplicate_count / total_rows) * 100\n",
        "data_quality_report['Duplicates'] = {\n",
        "    'Count': duplicate_count,\n",
        "    'Percentage': duplicate_percentage\n",
        "}\n",
        "\n",
        "print(\"Data quality report populated with summaries.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data quality report populated with summaries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e5502c7"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the data quality report is populated, I will create the 'Before vs After' comparison summary, drawing on the initial data profiling and the results of the cleaning and flagging steps. Finally, I will print both the `data_quality_report` and the `before_after_summary` to fulfill the subtask requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a68862ff",
        "outputId": "3cc452e7-c8f4-4be2-81a3-28fe72e9dd94"
      },
      "source": [
        "before_after_summary = {}\n",
        "\n",
        "total_rows = cleaned_df.shape[0]\n",
        "\n",
        "# Missing Values Comparison\n",
        "before_missing_brand = missing_data_report.loc['Brand', 'Missing Count']\n",
        "before_missing_division = missing_data_report.loc['Division', 'Missing Count']\n",
        "before_missing_category = missing_data_report.loc['Category', 'Missing Count']\n",
        "before_missing_subcategory = missing_data_report.loc['Subcategory', 'Missing Count']\n",
        "before_missing_segment = missing_data_report.loc['Segment', 'Missing Count']\n",
        "\n",
        "before_after_summary['Missing Values (Categorical Columns)'] = {\n",
        "    'Before Cleaning (Count)': before_missing_brand + before_missing_division + before_missing_category + before_missing_subcategory + before_missing_segment,\n",
        "    'After Cleaning (Count)': 0 # All categorical missing values were filled\n",
        "}\n",
        "\n",
        "before_after_summary['Missing Values (product_id_numeric)'] = {\n",
        "    'Before Cleaning (Count)': cleaned_df['is_missing_original_product_id_numeric'].sum(),\n",
        "    'After Cleaning (Count)': 0 # Numerical missing values were filled with median\n",
        "}\n",
        "\n",
        "# Invalid product_id format comparison\n",
        "before_after_summary['Invalid product_id Format'] = {\n",
        "    'Before Cleaning (Count)': len(invalid_product_ids),\n",
        "    'After Cleaning (Flagged Count)': cleaned_df['is_invalid_product_id_format'].sum() # Flagged, not removed\n",
        "}\n",
        "\n",
        "# Duplicate Rows Comparison\n",
        "before_after_summary['Duplicate Rows'] = {\n",
        "    'Before Cleaning (Count)': len(duplicate_rows),\n",
        "    'After Cleaning (Flagged Count)': cleaned_df['is_duplicate'].sum() # Flagged, not removed\n",
        "}\n",
        "\n",
        "# Overall Validation Flag\n",
        "before_after_summary['Overall Flagged Rows (Validation Flag)'] = {\n",
        "    'Total Rows': total_rows,\n",
        "    'Flagged Rows Count': cleaned_df['validation_flag'].sum(),\n",
        "    'Flagged Rows Percentage': (cleaned_df['validation_flag'].sum() / total_rows) * 100\n",
        "}\n",
        "\n",
        "print(\"\\nData Quality Report:\")\n",
        "for section, content in data_quality_report.items():\n",
        "    print(f\"\\n{section}:\")\n",
        "    if isinstance(content, dict):\n",
        "        for key, value in content.items():\n",
        "            if isinstance(value, dict):\n",
        "                print(f\"  {key}:\")\n",
        "                for sub_key, sub_value in value.items():\n",
        "                    print(f\"    {sub_key}: {sub_value}\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value}\")\n",
        "    else:\n",
        "        print(f\"  {content}\")\n",
        "\n",
        "print(\"\\nBefore vs After Comparison Summary:\")\n",
        "for section, content in before_after_summary.items():\n",
        "    print(f\"\\n{section}:\")\n",
        "    for key, value in content.items():\n",
        "        print(f\"  {key}: {value}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Quality Report:\n",
            "\n",
            "Overall Data Quality Summary:\n",
            "  Total Rows: 62700\n",
            "  Total Flagged Rows (validation_flag): 39547\n",
            "  Percentage Flagged Rows: 63.07336523125997\n",
            "\n",
            "Missing Values (Original):\n",
            "  is_missing_original_brand:\n",
            "    Count: 3105\n",
            "    Percentage: 4.952153110047846\n",
            "  is_missing_original_division:\n",
            "    Count: 823\n",
            "    Percentage: 1.3125996810207337\n",
            "  is_missing_original_category:\n",
            "    Count: 823\n",
            "    Percentage: 1.3125996810207337\n",
            "  is_missing_original_subcategory:\n",
            "    Count: 823\n",
            "    Percentage: 1.3125996810207337\n",
            "  is_missing_original_segment:\n",
            "    Count: 823\n",
            "    Percentage: 1.3125996810207337\n",
            "  is_missing_original_product_id_numeric:\n",
            "    Count: 2\n",
            "    Percentage: 0.0031897926634768745\n",
            "\n",
            "Invalid Formats:\n",
            "  Count: 2\n",
            "  Percentage: 0.0031897926634768745\n",
            "\n",
            "Corrupted IDs:\n",
            "  Count: 39547\n",
            "  Percentage: 63.07336523125997\n",
            "\n",
            "Outliers:\n",
            "  Count: 0\n",
            "  Percentage: 0.0\n",
            "\n",
            "Negative Unit Price:\n",
            "  Count: 0\n",
            "  Percentage: 0.0\n",
            "\n",
            "Duplicates:\n",
            "  Count: 0\n",
            "  Percentage: 0.0\n",
            "\n",
            "Before vs After Comparison Summary:\n",
            "\n",
            "Missing Values (Categorical Columns):\n",
            "  Before Cleaning (Count): 6397\n",
            "  After Cleaning (Count): 0\n",
            "\n",
            "Missing Values (product_id_numeric):\n",
            "  Before Cleaning (Count): 2\n",
            "  After Cleaning (Count): 0\n",
            "\n",
            "Invalid product_id Format:\n",
            "  Before Cleaning (Count): 2\n",
            "  After Cleaning (Flagged Count): 2\n",
            "\n",
            "Duplicate Rows:\n",
            "  Before Cleaning (Count): 0\n",
            "  After Cleaning (Flagged Count): 0\n",
            "\n",
            "Overall Flagged Rows (Validation Flag):\n",
            "  Total Rows: 62700\n",
            "  Flagged Rows Count: 39547\n",
            "  Flagged Rows Percentage: 63.07336523125997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39efaa9c"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Review the generated `cleaned_df`, `data_quality_report`, and the Before vs After comparison summary. This step concludes the data cleaning and preparation process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "235432aa"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The initial dataset contained 62,700 rows and 8 columns. Key columns included `product_id`, `product_name`, `Brand`, `Division`, `Category`, `Subcategory`, `Segment`, and `unit_price`.\n",
        "*   **Missing Values (Initial State)**:\n",
        "    *   `Brand`: 3,105 values (4.95%) were missing.\n",
        "    *   `Division`, `Category`, `Subcategory`, `Segment`: 823 values each (1.31% each) were missing.\n",
        "    *   `unit_price`: No missing values.\n",
        "*   **Duplicate Rows**: No perfectly duplicate rows were found in the dataset.\n",
        "*   **Invalid Formats**:\n",
        "    *   Two rows had `product_id` values ('V', 'V1') that were non-numeric, indicating an invalid format.\n",
        "    *   `Brand` column showed inconsistent text formatting (e.g., casing, leading/trailing spaces), with 11,852 original unique values reducing to 11,848 after standardization.\n",
        "*   **Outliers**: No outliers were detected in the `unit_price` column using the IQR method.\n",
        "*   **Standardization**:\n",
        "    *   All column names were converted to snake\\_case (e.g., `product_id`, `unit_price`).\n",
        "    *   String columns were stripped of leading/trailing whitespace.\n",
        "    *   Categorical columns (`brand`, `division`, `category`, `subcategory`, `segment`) were standardized to Title Case, while `product_name` was converted to lowercase.\n",
        "*   **Missing Value Handling**:\n",
        "    *   Missing values in categorical columns were replaced with 'Unknown'.\n",
        "    *   The 2 missing `product_id_numeric` values were imputed with the column's median (3,012,287,777.0).\n",
        "    *   Boolean flag columns (e.g., `is_missing_original_brand`, `is_missing_original_product_id_numeric`) were created to indicate original missingness, with a total of 6,397 original missing categorical values and 2 original missing numeric product IDs.\n",
        "*   **ID Validation and Business Logic**:\n",
        "    *   **`is_invalid_format`**: Two rows were flagged due to non-numeric `product_id` values.\n",
        "    *   **`is_corrupted_id`**: A significant 39,547 rows (63.07%) were flagged because their `product_id` was either non-numeric or not a 13-digit integer.\n",
        "    *   **`is_negative_unit_price`**: No rows had negative unit prices.\n",
        "    *   **`is_outlier`**: No outliers were detected in `unit_price`.\n",
        "*   **Combined Validation Flag**: A `validation_flag` identified 39,547 rows (63.07% of the dataset) with at least one critical data quality issue (primarily corrupted IDs or invalid ID format).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Address Corrupted IDs**: Given that 63.07% of products have corrupted IDs, immediate action is required to investigate the source of this widespread issue. This could involve data source verification or a more robust ID generation/capture process.\n",
        "*   **Utilize Flag Columns**: The `cleaned_df` with its comprehensive set of flag columns can be used for downstream analysis, allowing analysts to filter out or specifically analyze problematic data points without losing the original context or values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5bed3db",
        "outputId": "7a3de94e-de20-4b14-f0e4-2badfda00949"
      },
      "source": [
        "# Save the cleaned_df to a CSV file\n",
        "cleaned_df.to_csv('cleaned_products_dimension.csv', index=False)\n",
        "print(\"cleaned_products_dimension.csv saved successfully.\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cleaned_products_dimension.csv saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "d5a962c0",
        "outputId": "cfba7b9e-ce27-4955-adf6-87fde16c5916"
      },
      "source": [
        "display(cleaned_df.head())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    product_id                              product_name         brand  \\\n",
              "0  5.28102E+12          beesline elder rose deo r.on 50m  beesline deo   \n",
              "1  5.28102E+12  beesline green forst whit.r.on deod.50m#  beesline deo   \n",
              "2  5.28102E+12    beesline pacific islands deo r.on 50m#  beesline deo   \n",
              "3  5.28102E+12         beesline cool breeze deo r.on 50m  beesline deo   \n",
              "4  5.28102E+12        beesline hr delaying deo r.on 50m#  beesline deo   \n",
              "\n",
              "              division         category      subcategory         segment  \\\n",
              "0  everyday essentials  body fresheners  lady fresheners  lady deodorant   \n",
              "1  everyday essentials  body fresheners  lady fresheners  lady deodorant   \n",
              "2  everyday essentials  body fresheners  lady fresheners  lady deodorant   \n",
              "3  everyday essentials  body fresheners  lady fresheners  lady deodorant   \n",
              "4  everyday essentials  body fresheners  lady fresheners  lady deodorant   \n",
              "\n",
              "   unit_price  product_id_numeric  is_invalid_product_id_format  ...  \\\n",
              "0       40.58     5281020000000.0                         False  ...   \n",
              "1       95.32     5281020000000.0                         False  ...   \n",
              "2       74.54     5281020000000.0                         False  ...   \n",
              "3       61.87     5281020000000.0                         False  ...   \n",
              "4       19.82     5281020000000.0                         False  ...   \n",
              "\n",
              "   is_missing_original_category  is_missing_original_subcategory  \\\n",
              "0                         False                            False   \n",
              "1                         False                            False   \n",
              "2                         False                            False   \n",
              "3                         False                            False   \n",
              "4                         False                            False   \n",
              "\n",
              "   is_missing_original_segment  is_missing_original_product_id_numeric  \\\n",
              "0                        False                                   False   \n",
              "1                        False                                   False   \n",
              "2                        False                                   False   \n",
              "3                        False                                   False   \n",
              "4                        False                                   False   \n",
              "\n",
              "   is_corrupted_id  is_invalid_format  is_negative_unit_price  is_outlier  \\\n",
              "0            False              False                   False       False   \n",
              "1            False              False                   False       False   \n",
              "2            False              False                   False       False   \n",
              "3            False              False                   False       False   \n",
              "4            False              False                   False       False   \n",
              "\n",
              "   validation_flag  is_duplicate  \n",
              "0            False         False  \n",
              "1            False         False  \n",
              "2            False         False  \n",
              "3            False         False  \n",
              "4            False         False  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa61084d-851b-4af9-b56b-79f4f1a606fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_name</th>\n",
              "      <th>brand</th>\n",
              "      <th>division</th>\n",
              "      <th>category</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>segment</th>\n",
              "      <th>unit_price</th>\n",
              "      <th>product_id_numeric</th>\n",
              "      <th>is_invalid_product_id_format</th>\n",
              "      <th>...</th>\n",
              "      <th>is_missing_original_category</th>\n",
              "      <th>is_missing_original_subcategory</th>\n",
              "      <th>is_missing_original_segment</th>\n",
              "      <th>is_missing_original_product_id_numeric</th>\n",
              "      <th>is_corrupted_id</th>\n",
              "      <th>is_invalid_format</th>\n",
              "      <th>is_negative_unit_price</th>\n",
              "      <th>is_outlier</th>\n",
              "      <th>validation_flag</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.28102E+12</td>\n",
              "      <td>beesline elder rose deo r.on 50m</td>\n",
              "      <td>beesline deo</td>\n",
              "      <td>everyday essentials</td>\n",
              "      <td>body fresheners</td>\n",
              "      <td>lady fresheners</td>\n",
              "      <td>lady deodorant</td>\n",
              "      <td>40.58</td>\n",
              "      <td>5281020000000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.28102E+12</td>\n",
              "      <td>beesline green forst whit.r.on deod.50m#</td>\n",
              "      <td>beesline deo</td>\n",
              "      <td>everyday essentials</td>\n",
              "      <td>body fresheners</td>\n",
              "      <td>lady fresheners</td>\n",
              "      <td>lady deodorant</td>\n",
              "      <td>95.32</td>\n",
              "      <td>5281020000000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.28102E+12</td>\n",
              "      <td>beesline pacific islands deo r.on 50m#</td>\n",
              "      <td>beesline deo</td>\n",
              "      <td>everyday essentials</td>\n",
              "      <td>body fresheners</td>\n",
              "      <td>lady fresheners</td>\n",
              "      <td>lady deodorant</td>\n",
              "      <td>74.54</td>\n",
              "      <td>5281020000000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.28102E+12</td>\n",
              "      <td>beesline cool breeze deo r.on 50m</td>\n",
              "      <td>beesline deo</td>\n",
              "      <td>everyday essentials</td>\n",
              "      <td>body fresheners</td>\n",
              "      <td>lady fresheners</td>\n",
              "      <td>lady deodorant</td>\n",
              "      <td>61.87</td>\n",
              "      <td>5281020000000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.28102E+12</td>\n",
              "      <td>beesline hr delaying deo r.on 50m#</td>\n",
              "      <td>beesline deo</td>\n",
              "      <td>everyday essentials</td>\n",
              "      <td>body fresheners</td>\n",
              "      <td>lady fresheners</td>\n",
              "      <td>lady deodorant</td>\n",
              "      <td>19.82</td>\n",
              "      <td>5281020000000.0</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa61084d-851b-4af9-b56b-79f4f1a606fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa61084d-851b-4af9-b56b-79f4f1a606fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa61084d-851b-4af9-b56b-79f4f1a606fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbc3137"
      },
      "source": [
        "### Additional Text Column Refinement\n",
        "\n",
        "**Reasoning:**\n",
        "This step, provided by the user, explicitly converts specified text columns to string type, trims whitespace, replaces various empty string representations with `NaN`, and converts all text to lowercase. This is a crucial step to ensure consistency and proper identification of missing values within text fields before final imputation. While some of these operations were previously covered, this snippet adds explicit `astype('string')` and comprehensive `replace` logic for empty/placeholder strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bf78268",
        "outputId": "59098818-2c28-4909-d97d-211d1ba8f938"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# الأعمدة المطلوبة\n",
        "text_columns = [\n",
        "    \"brand\",\n",
        "    \"division\",\n",
        "    \"category\",\n",
        "    \"subcategory\",\n",
        "    \"segment\",\n",
        "    \"product_name\"\n",
        "]\n",
        "\n",
        "# نتأكد إن الأعمدة موجودة\n",
        "existing_cols = [col for col in text_columns if col in df.columns]\n",
        "\n",
        "for col in existing_cols:\n",
        "\n",
        "    # تحويل إلى string لتجنب مشاكل الـ dtype\n",
        "    df[col] = df[col].astype(\"string\")\n",
        "\n",
        "    # إزالة المسافات الزائدة\n",
        "    df[col] = df[col].str.strip()\n",
        "\n",
        "    # استبدال القيم الفارغة النصية بـ NaN\n",
        "    df[col] = df[col].replace([\"\", \" \", \"nan\", \"None\"], np.nan)\n",
        "\n",
        "    # توحيد شكل النص (اختياري)\n",
        "    df[col] = df[col].str.lower()\n",
        "\n",
        "    # استبدال القيم المفقودة بـ unknown\n",
        "    df[col] = df[col].fillna(\"unknown\")\n",
        "\n",
        "print(\"Cleaning completed successfully ✅\")\n",
        "print(\"\\nDataFrame head after additional text cleaning:\")\n",
        "print(df.head())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning completed successfully ✅\n",
            "\n",
            "DataFrame head after additional text cleaning:\n",
            "    product_id                              product_name         brand  \\\n",
            "0  5.28102E+12          beesline elder rose deo r.on 50m  beesline deo   \n",
            "1  5.28102E+12  beesline green forst whit.r.on deod.50m#  beesline deo   \n",
            "2  5.28102E+12    beesline pacific islands deo r.on 50m#  beesline deo   \n",
            "3  5.28102E+12         beesline cool breeze deo r.on 50m  beesline deo   \n",
            "4  5.28102E+12        beesline hr delaying deo r.on 50m#  beesline deo   \n",
            "\n",
            "              division         category      subcategory         segment  \\\n",
            "0  everyday essentials  body fresheners  lady fresheners  lady deodorant   \n",
            "1  everyday essentials  body fresheners  lady fresheners  lady deodorant   \n",
            "2  everyday essentials  body fresheners  lady fresheners  lady deodorant   \n",
            "3  everyday essentials  body fresheners  lady fresheners  lady deodorant   \n",
            "4  everyday essentials  body fresheners  lady fresheners  lady deodorant   \n",
            "\n",
            "   unit_price  product_id_numeric  is_invalid_product_id_format  ...  \\\n",
            "0       40.58     5281020000000.0                         False  ...   \n",
            "1       95.32     5281020000000.0                         False  ...   \n",
            "2       74.54     5281020000000.0                         False  ...   \n",
            "3       61.87     5281020000000.0                         False  ...   \n",
            "4       19.82     5281020000000.0                         False  ...   \n",
            "\n",
            "   is_missing_original_category  is_missing_original_subcategory  \\\n",
            "0                         False                            False   \n",
            "1                         False                            False   \n",
            "2                         False                            False   \n",
            "3                         False                            False   \n",
            "4                         False                            False   \n",
            "\n",
            "   is_missing_original_segment  is_missing_original_product_id_numeric  \\\n",
            "0                        False                                   False   \n",
            "1                        False                                   False   \n",
            "2                        False                                   False   \n",
            "3                        False                                   False   \n",
            "4                        False                                   False   \n",
            "\n",
            "   is_corrupted_id  is_invalid_format  is_negative_unit_price  is_outlier  \\\n",
            "0            False              False                   False       False   \n",
            "1            False              False                   False       False   \n",
            "2            False              False                   False       False   \n",
            "3            False              False                   False       False   \n",
            "4            False              False                   False       False   \n",
            "\n",
            "   validation_flag  is_duplicate  \n",
            "0            False         False  \n",
            "1            False         False  \n",
            "2            False         False  \n",
            "3            False         False  \n",
            "4            False         False  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48840013"
      },
      "source": [
        "# Task\n",
        "Perform a comprehensive data cleaning, quality assessment, and flagging process on the \"products_dimension.csv\" file. This includes loading the data, profiling, identifying data quality issues (missing values, duplicates, invalid formats, outliers, inconsistent text), standardizing data formats, handling missing values by replacement and flagging original missingness, validating IDs and other data formats, applying business logic validations and flagging issues, detecting and flagging duplicate rows, and finally, generating a cleaned DataFrame along with a detailed data quality report and a 'Before vs After' comparison summary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f577f26f"
      },
      "source": [
        "## Generate Final Output and Report (Re-run)\n",
        "\n",
        "### Subtask:\n",
        "Re-construct the final `cleaned_df` from the latest state of `df`, then re-generate the comprehensive `data_quality_report` dictionary and the 'Before vs After' comparison summary to include the effects of the recent text cleaning step. This ensures all reports are up-to-date.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40f07901"
      },
      "source": [
        "**Reasoning**:\n",
        "I will re-create `cleaned_df` from the current state of `df` to capture all the latest cleaning changes. Then, I will re-initialize the `data_quality_report` and `before_after_summary` dictionaries to ensure they reflect the most up-to-date information, including the effects of the recent text cleaning step. Finally, I will populate these reports with the requested metrics and comparisons, and print them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b83d7d8",
        "outputId": "661d8307-e95c-4b71-b240-77eb7c7b9f05"
      },
      "source": [
        "cleaned_df = df.copy()\n",
        "\n",
        "data_quality_report = {}\n",
        "before_after_summary = {}\n",
        "\n",
        "total_rows = cleaned_df.shape[0]\n",
        "\n",
        "# Overall Data Quality Summary\n",
        "data_quality_report['Overall Data Quality Summary'] = {\n",
        "    'Total Rows': total_rows,\n",
        "    'Total Flagged Rows (validation_flag)': cleaned_df['validation_flag'].sum(),\n",
        "    'Percentage Flagged Rows': (cleaned_df['validation_flag'].sum() / total_rows) * 100\n",
        "}\n",
        "\n",
        "# Missing Values (Original)\n",
        "data_quality_report['Missing Values (Original)'] = {}\n",
        "original_missing_cols = [col for col in cleaned_df.columns if col.startswith('is_missing_original_')]\n",
        "for col in original_missing_cols:\n",
        "    count = cleaned_df[col].sum()\n",
        "    percentage = (count / total_rows) * 100\n",
        "    data_quality_report['Missing Values (Original)'][col] = {\n",
        "        'Count': count,\n",
        "        'Percentage': percentage\n",
        "    }\n",
        "\n",
        "# Invalid Formats\n",
        "invalid_format_count = cleaned_df['is_invalid_format'].sum()\n",
        "invalid_format_percentage = (invalid_format_count / total_rows) * 100\n",
        "data_quality_report['Invalid Formats'] = {\n",
        "    'Count': invalid_format_count,\n",
        "    'Percentage': invalid_format_percentage\n",
        "}\n",
        "\n",
        "# Corrupted IDs\n",
        "corrupted_id_count = cleaned_df['is_corrupted_id'].sum()\n",
        "corrupted_id_percentage = (corrupted_id_count / total_rows) * 100\n",
        "data_quality_report['Corrupted IDs'] = {\n",
        "    'Count': corrupted_id_count,\n",
        "    'Percentage': corrupted_id_percentage\n",
        "}\n",
        "\n",
        "# Outliers\n",
        "outlier_count = cleaned_df['is_outlier'].sum()\n",
        "outlier_percentage = (outlier_count / total_rows) * 100\n",
        "data_quality_report['Outliers'] = {\n",
        "    'Count': outlier_count,\n",
        "    'Percentage': outlier_percentage\n",
        "}\n",
        "\n",
        "# Negative Unit Price\n",
        "negative_unit_price_count = cleaned_df['is_negative_unit_price'].sum()\n",
        "negative_unit_price_percentage = (negative_unit_price_count / total_rows) * 100\n",
        "data_quality_report['Negative Unit Price'] = {\n",
        "    'Count': negative_unit_price_count,\n",
        "    'Percentage': negative_unit_price_percentage\n",
        "}\n",
        "\n",
        "# Duplicates\n",
        "duplicate_count = cleaned_df['is_duplicate'].sum()\n",
        "duplicate_percentage = (duplicate_count / total_rows) * 100\n",
        "data_quality_report['Duplicates'] = {\n",
        "    'Count': duplicate_count,\n",
        "    'Percentage': duplicate_percentage\n",
        "}\n",
        "\n",
        "# Before vs After Comparison Summary\n",
        "\n",
        "# Missing Values (Categorical Columns)\n",
        "before_missing_brand = missing_data_report.loc['Brand', 'Missing Count']\n",
        "before_missing_division = missing_data_report.loc['Division', 'Missing Count']\n",
        "before_missing_category = missing_data_report.loc['Category', 'Missing Count']\n",
        "before_missing_subcategory = missing_data_report.loc['Subcategory', 'Missing Count']\n",
        "before_missing_segment = missing_data_report.loc['Segment', 'Missing Count']\n",
        "\n",
        "before_after_summary['Missing Values (Categorical Columns)'] = {\n",
        "    'Before Cleaning (Count)': before_missing_brand + before_missing_division + before_missing_category + before_missing_subcategory + before_missing_segment,\n",
        "    'After Cleaning (Count)': 0 # All categorical missing values were filled\n",
        "}\n",
        "\n",
        "before_after_summary['Missing Values (product_id_numeric)'] = {\n",
        "    'Before Cleaning (Count)': cleaned_df['is_missing_original_product_id_numeric'].sum(),\n",
        "    'After Cleaning (Count)': 0 # Numerical missing values were filled with median\n",
        "}\n",
        "\n",
        "# Invalid product_id format comparison\n",
        "before_after_summary['Invalid product_id Format'] = {\n",
        "    'Before Cleaning (Count)': len(invalid_product_ids),\n",
        "    'After Cleaning (Flagged Count)': cleaned_df['is_invalid_product_id_format'].sum() # Flagged, not removed\n",
        "}\n",
        "\n",
        "# Duplicate Rows Comparison\n",
        "before_after_summary['Duplicate Rows'] = {\n",
        "    'Before Cleaning (Count)': len(duplicate_rows),\n",
        "    'After Cleaning (Flagged Count)': cleaned_df['is_duplicate'].sum() # Flagged, not removed\n",
        "}\n",
        "\n",
        "# Overall Validation Flag\n",
        "before_after_summary['Overall Flagged Rows (Validation Flag)'] = {\n",
        "    'Total Rows': total_rows,\n",
        "    'Flagged Rows Count': cleaned_df['validation_flag'].sum(),\n",
        "    'Flagged Rows Percentage': (cleaned_df['validation_flag'].sum() / total_rows) * 100\n",
        "}\n",
        "\n",
        "print(\"\\nData Quality Report:\")\n",
        "for section, content in data_quality_report.items():\n",
        "    print(f\"\\n{section}:\")\n",
        "    if isinstance(content, dict):\n",
        "        for key, value in content.items():\n",
        "            if isinstance(value, dict):\n",
        "                print(f\"  {key}:\")\n",
        "                for sub_key, sub_value in value.items():\n",
        "                    print(f\"    {sub_key}: {sub_value}\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value}\")\n",
        "    else:\n",
        "        print(f\"  {content}\")\n",
        "\n",
        "print(\"\\nBefore vs After Comparison Summary:\")\n",
        "for section, content in before_after_summary.items():\n",
        "    print(f\"\\n{section}:\")\n",
        "    for key, value in content.items():\n",
        "        print(f\"  {key}: {value}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Quality Report:\n",
            "\n",
            "Overall Data Quality Summary:\n",
            "  Total Rows: 62700\n",
            "  Total Flagged Rows (validation_flag): 39547\n",
            "  Percentage Flagged Rows: 63.07336523125997\n",
            "\n",
            "Missing Values (Original):\n",
            "  is_missing_original_brand:\n",
            "    Count: 3105\n",
            "    Percentage: 4.952153110047846\n",
            "  is_missing_original_division:\n",
            "    Count: 823\n",
            "    Percentage: 1.3125996810207337\n",
            "  is_missing_original_category:\n",
            "    Count: 823\n",
            "    Percentage: 1.3125996810207337\n",
            "  is_missing_original_subcategory:\n",
            "    Count: 823\n",
            "    Percentage: 1.3125996810207337\n",
            "  is_missing_original_segment:\n",
            "    Count: 823\n",
            "    Percentage: 1.3125996810207337\n",
            "  is_missing_original_product_id_numeric:\n",
            "    Count: 2\n",
            "    Percentage: 0.0031897926634768745\n",
            "\n",
            "Invalid Formats:\n",
            "  Count: 2\n",
            "  Percentage: 0.0031897926634768745\n",
            "\n",
            "Corrupted IDs:\n",
            "  Count: 39547\n",
            "  Percentage: 63.07336523125997\n",
            "\n",
            "Outliers:\n",
            "  Count: 0\n",
            "  Percentage: 0.0\n",
            "\n",
            "Negative Unit Price:\n",
            "  Count: 0\n",
            "  Percentage: 0.0\n",
            "\n",
            "Duplicates:\n",
            "  Count: 0\n",
            "  Percentage: 0.0\n",
            "\n",
            "Before vs After Comparison Summary:\n",
            "\n",
            "Missing Values (Categorical Columns):\n",
            "  Before Cleaning (Count): 6397\n",
            "  After Cleaning (Count): 0\n",
            "\n",
            "Missing Values (product_id_numeric):\n",
            "  Before Cleaning (Count): 2\n",
            "  After Cleaning (Count): 0\n",
            "\n",
            "Invalid product_id Format:\n",
            "  Before Cleaning (Count): 2\n",
            "  After Cleaning (Flagged Count): 2\n",
            "\n",
            "Duplicate Rows:\n",
            "  Before Cleaning (Count): 0\n",
            "  After Cleaning (Flagged Count): 0\n",
            "\n",
            "Overall Flagged Rows (Validation Flag):\n",
            "  Total Rows: 62700\n",
            "  Flagged Rows Count: 39547\n",
            "  Flagged Rows Percentage: 63.07336523125997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fa3248c"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Review the generated `cleaned_df`, `data_quality_report`, and the Before vs After comparison summary. This step concludes the data cleaning and preparation process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c50677f"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Overall Data Quality:** Out of 62,700 total rows, 39,547 rows (63.07%) were flagged by the `validation_flag`, indicating a significant number of data quality issues or business rule violations.\n",
        "*   **Corrupted IDs are Dominant:** The primary contributor to flagged rows is corrupted product IDs, affecting 39,547 rows (63.07% of the dataset). This aligns directly with the overall flagged row count.\n",
        "*   **Missing Values (Original):**\n",
        "    *   'Brand' had 3,105 original missing values (4.95%).\n",
        "    *   'Division', 'Category', 'Subcategory', and 'Segment' each had 823 original missing values (1.31%).\n",
        "    *   'product\\_id\\_numeric' had 2 original missing values (0.003%).\n",
        "*   **Missing Value Handling Effectiveness:** All 6,397 original missing values in categorical columns and 2 missing values in 'product\\_id\\_numeric' were successfully handled (filled) during the cleaning process, resulting in 0 missing values for these categories after cleaning.\n",
        "*   **Invalid Formats:** 2 rows (0.003%) were identified and flagged for invalid formats, specifically concerning `product_id`.\n",
        "*   **No Outliers or Negative Unit Prices:** The analysis found 0 outliers and 0 instances of negative unit prices.\n",
        "*   **No Duplicate Rows:** The dataset did not contain any duplicate rows, either before or after the cleaning process.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Address Corrupted IDs:** The high percentage of corrupted IDs (63.07%) is a critical issue. Future steps should involve a deep dive into the source of these corrupted IDs and implementing measures to prevent them. It's crucial to determine if these rows are salvageable or if they should be excluded from analysis.\n",
        "*   **Review Validation Criteria:** Given the high number of flagged rows, it would be beneficial to review the business logic and validation criteria that led to such a high flagging rate. This ensures that the flags accurately reflect actionable data quality problems rather than overly strict or misapplied rules.\n"
      ]
    }
  ]
}